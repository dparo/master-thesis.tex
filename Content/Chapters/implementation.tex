\chapter{Implementation}
\label{sec:implementation-chapter}

This chapter introduces the proposed branch-and-cut algorithm (BAC).
The BAC algorithm was implemented using the recent \textit{CPLEX 22.1 C callable library}.
\textit{CPLEX version 22.1} was released in March 2022.
The proposed branch-and-cut uses the CPTP formulation as the foundational static IP model.
Refer to the previous discussion on the CPTP in \cref{sec:the-capacitated-profitable-tour-problem} for more information.
By appropriately defining the profit function associated with each vertex $p_i \quad \forall i \in V$,
our framework can be utilized as a pricer inside a column generation approach for the standard CVRP.
The BAC's source code was developed in \textit{C}.
The source code is freely available under a permissive \texttt{MIT license}
at the following \textit{Github} repository: \url{https://github.com/dparo/master-thesis}.

\medskip

\urlref{https://www.ibm.com/analytics/cplex-optimizer}{IBM ILOG CPLEX Optimizer},
CPLEX for short,
is a commercial optimization software package for solving problems expressed as either:
linear programs, mixed-integer programs, quadratic programs, or quadratically constrained programs.
For an introduction to CPLEX refer to \cref{sec:introduction-to-cplex}.

The CPLEX optimizer is heavily used in our branch-and-cut implementation
to solve the associated CPTP MIP model.
The cutting planes separation was implemented using \textit{CPLEX generic callback functions},
which has the advantage of not disabling the \textit{Dynamic Search algorithm}.
The \textit{Dynamic Search} is the CPLEX's internal advanced proprietary branch-and-cut algorithm,
as discussed in \cref{sec:introduction-to-cplex}.

Using a modern MIP solver, such as CPLEX, may provide at least two advantages
over tailored pricer algorithms, such as the labeling algorithm \parencite{desrochers1992, feillet2004}:
(i) parallelization and efficient use of the machine's multiple cores basically for free,
(ii) take advantage of all the engineering effort that went into creating an efficient MIP solver
(preprocessing, diving, fixing, primal heuristics, and more).
However, there are drawbacks to such an approach.
Complicated relaxations or constraints, such as the ng-sets \parencite{baldacci2011},
may be impractical to implement efficiently within a BAC algorithm.

\medskip

This chapter's outline is quickly summarized.
The implemented static IP model is presented in \cref{sec:impl-full-static-model}.
\Cref{sec:impl-warm-starting} describes the implemented primal heuristics for \textit{warm starting} the MIP optimizer.
\Cref{sec:impl-branching} discusses the implemented branching scheme.
Finally, \cref{sec:impl-separation-techniques} describes the cutting planes strategies used, including a discussion of the separation techniques used.

\section{Full static model}
\label{sec:impl-full-static-model}

Our static IP model is based on a minor modification of the CPTP formulation
\labelcref{eq:cptp-obj-function,eq:cptp-depot-part-of-tour-constraint,eq:cptp-resource-upper-bound-constraint,eq:cptp-flow-conservation-constraint,eq:cptp-gsec-constraints,eq:cptp-x-mip-var-bounds,eq:cptp-y-mip-var-bounds}
by disregarding the GSECs inequalities \labelcref{eq:cptp-gsec-constraints}.
Upon violation,
the GSECs will be exactly separated lazily to ensure the approach's correctness.

We've implemented the following static Integer Programme (IP) model:
\begin{align}
	\min_{x,y} \quad z_\mt{CPTP}(x, y) & = \ExprCptpObjValDef                     & \label{eq:cptp-static-model-0}                         \\
	                                   & y_0 = 1                                  & \label{eq:cptp-static-model-1}                         \\
	                                   & B \le   \ExprCptpDemandSum   \le Q       & \label{eq:cptp-static-model-2}                         \\
	                                   & \ExprCptpEdgesIncident{i}    = 2 y_i     & \quad \forall i \in V  \label{eq:cptp-static-model-3}  \\
	                                   & x_{e}                   \in \Set*{0, 1}  & \quad \forall e \in E  \label{eq:cptp-static-model-4}  \\
	                                   & y_{i}                    \in \Set*{0, 1} & \quad \forall i \in V  \label{eq:cptp-static-model-5},
\end{align}
where
$B \in R_+$ is an additional lower bound on the resource consumption
that may help in gaining a slight improvement on the linear relaxation.
The value of $B$ is computed as $B = q_u + q_v$, where $u, v \in V_0,\ u \ne v$
represent the least two demanding customers in the network:
$q_u \le q_v \le q_i \quad \forall i \in V_0, i \ne u, v$.

\subsection{Upper cutoff value}
\label{sec:impl-upper-cutoff-value}

In the context of CVRP pricing, we're only interested in routes achieving a strictly negative cost function.
A MIP optimizer can use the \textit{upper cutoff value} to reduce the number of evaluated branch-and-bound nodes.
The upper cutoff value acts as a direct constraint on the objective function:
\begin{equation}
	z_\mt{CPTP}(x, y) \le 0 - \varepsilon_{\mt{ct}},
\end{equation}
where $\varepsilon_{\mt{ct}} \in \R_+$ denotes the upper cutoff tolerance.
Most MIP solvers, including CPLEX, has internal support for specifying cutoff values.
However, fixing the cutoff value is not the same as specifying an explicit constraint in the static model.
Only when the branch-and-bound procedure is invoked, do cutoff values contribute.
An explicit constraint, on the other hand, contributes even at the linear relaxation level.
The upper cutoff tolerance $\varepsilon_{\mt{ct}}$ biases the threshold at which a produced route
can be considered a valid reduced cost column.
A non-zero value for $\varepsilon_{\mt{ct}}$ avoids numerical
stability problems caused by the usage of floating-point arithmetic
employed in BPC implementations.

To ensure correctness, the value of $\varepsilon_{\mt{ct}}$ must match the value used by the BPC algorithm.
In our case, we chose $\varepsilon_{\mt{ct}} = 10^{-6}$ because it is the value used by the modern BPC framework described in \textcite{sadykov2021}.

\section{Warm Starting}
\label{sec:impl-warm-starting}

\textit{Warm starting} is a technique that involves feeding
a MIP optimizer with (good) feasible solutions
before beginning the resolution process.
Having a set of (good) initial feasible solutions
can significantly reduce the primal-dual bound gap,
as a result, the amount of time required to achieve optimality.
Warm starting can be applied to a wide range of IP problem domains,
and it is usually supported by the market's leading MIP solvers,
such as CPLEX.

Primal heuristics offer a quick and practical approach to warm starting.
A CPTP problem is very similar to a TSP problem.
As a result, TSP's heuristics are fine-tunable to work successfully even with the CPTP.
Many contributions were dedicated to researching good heuristics for the TSP,
see \cite{rosenkrantz1977, johnson1997, laporte1992, johnson2007, hoffman2013}.

\medskip

The warm starting procedure that we've implemented is explained in the remainder of this section.
The procedure is divided into two stages:
a constructive insertion heuristic stage (see \cref{sec:impl-insertion-heuristic})
followed by a 2-OPT refinement stage (see \cref{sec:impl-2opt-refinement}),

\subsection{Insertion heuristic}
\label{sec:impl-insertion-heuristic}

\cite{rosenkrantz1977} do an excellent job of describing the TSP's insertion heuristic algorithm
and various facets in which it can be implemented.
In $\Theta(N^2)$ time, the insertion heuristic algorithm can generate a new feasible primal solution.
In this section,
we modify the TSP insertion heuristic
to make it work with the CPTP.

\medskip

Start by selecting two distinct nodes $u, v \in V,\ q_u + q_v \le Q$
to form an initial tour back-to-back $p = \Tuple*{u, v}$.

The insertion heuristic algorithm is an iterative approach
in which an almost-feasible CPTP tour is available at each iteration.
If the CPTP admits feasible solutions,
the final available tour will undoubtedly be feasible
when all iterations of the insertion heuristic are exhausted.
Let's define $q(p) \le Q$ as the total demand served
by the partial route in this iteration.
Choose a vertex $a \in p$ and a vertex $h \notin p$ for each iteration.
Let's define $b$ as the successor of node $a$ in the current tour.
The goal is to insert $h$ in the tour
by deleting edge $\Tuple*{a, b}$
and inserting edges $\Tuple*{a, h},\ \Tuple*{h, b}$.
Only perform the insertion operation if the $h$ insertion
is required to restore feasibility or if its insertion lowers the route cost.
Let us define the extra mileage more formally as follows:
\begin{equation}
	\Delta_m(h, a) =
	\begin{cases}
		c_{ah} + c_{hb} - c_{ab} - p_h, & \texttt{if } q(p) + q_h \le Q \\
		\infty,                         & \texttt{otherwise},
	\end{cases}
\end{equation}
which represents the delta route cost in inserting $h$ as the successor of node $a$.
A vertex $h \in V$ is a good candidate for insertion
if at least one of the following conditions is met:
\begin{enumerate}
	\item $\Delta_m(h, a) < 0$, i.e. inserting $h$ improves over the current route.
	\item $h = 0$, i.e. $h$ is the depot node.
	      When the insertion candidate coincides with the depot,
	      regardless of whether its insertion is convenient, it must occur sooner or later.
	      Because we have defined $q_0 = 0$ by convention,
	      $q(p) + q_0 \le Q$ is always satisfied for the depot node.
	\item The number of visited nodes in the current tour is $2$ and $q(p) + q_h \le Q$.
\end{enumerate}

Prior to insertion the partial route has the form $p = \Tuple*{\dots, a, b, \dots}$;
whereas after the insertion operation completes: $p = \Tuple*{\dots, a, h, b, \dots}$.
In our implementation we employed the \textit{cheapest insertion scheme},
which means that the pair $(h, a)$ is chosen to minimize the extra mileage $\Delta_m(h, a)$
across all possible choices for $a \in p,\ h \notin p$.
When there are no further $h$ candidate vertices can be found, the algorithm stops.
At the end of the insertion heuristic, $p$ is a valid route that visits the depot node.
The depot node may not necessarily be the first element of the tour: $p_0 \ne 0$.
A simple circular rotation is all that is required to restore the condition $p_0 = 0$.
If no valid $h$ candidate can be found while the tour length is $2$,
we can conclude that the CPTP formulation does not admit any feasible solution
before even solving the IP formulation.

In our implementation we chose $u = 0$ and $v \in V_0$ so that $q_u + q_v \le Q$.
This approach allows us to generate $O(N)$ acceptable feasible primal solutions in $O(N^3)$ time.

\subsection{2-OPT refinement}
\label{sec:impl-2opt-refinement}

Each solution produced from the insertion heuristic
can be further improved using a \textit{2-OPT refinement procedure}.
The 2-OPT algorithm is a heuristic local-search hill-climbing procedure
proposed originally for the TSP in \textcite{flood1956, croes1958} independently.

The 2-OPT algorithm works iteratively in $\Omega(N^2)$ number of iterations.
Unfortunately,
as \textcite{chandra1999} points out,
the 2-OPT procedure may take an exponential number of iterations
when fed with purposefully artificially constructed instances.
Although this is unfortunate, it is also worth noting that in practice.
The probabilistic average number of iterations required for 2-OPT is at most polynomial.

Each iteration of the 2-OPT procedure looks for an existing edge crossing and, if found,
performs a 2-OPT exchange to undo it.
A 2-OPT exchange is a \textit{primal operation},
which means that its use preserves route feasibility.
Because 2-OPT exchange does not add nor remove vertices from the current route $p$,
the route's gained profit does not change during
the 2-OPT procedure's execution time.
As a result, adapting the original TSP's 2-OPT procedure to the CPTP problem becomes trivial.

Let $a, b \in p$ represent two vertices visited along the current route $p$.
Let $a^\prime, b^\prime \in p$ denote respectively the successor of $a$ and $b$ in the current route $p$.
A 2-OPT exchange replaces edges $(a, a^\prime)$, $(b, b^\prime)$
with $(a, b)$, $(a^\prime, b^\prime)$
but only if the delta distance, defined as:
\begin{equation}
	\Delta(a, b) = c_{a b} + c_{a^\prime b^\prime} - c_{a a^\prime} - c_{b b^\prime},
\end{equation}
satisfies $\Delta(a, b) < 0$.
In this case, a 2-OPT exchange over vertices $(a, b)$ reduces the route cost.
Following a 2-OPT exchange, the portion of the route $[a_s, \dots, b]$
denoted by head $a_s$ and tail $b$ must be reversed.

In our implementation
we look for vertices $a, b$ achieving the cheapest exchange,
that is, the delta distance $\Delta(a, b)$ is minimized
across all possible valid choices of $a, b \in p$.
The local search algorithms terminates when $\nexists (a, b) \mid a, b \in p,\ \Delta(a, b) < 0$.

\section{Branching}
\label{sec:impl-branching}

We don't implement any specific branching schemes.
We rely on the branching schemes already provided by the CPLEX MIP optimizer.

\section{Cutting planes and Inequalities separation}
\label{sec:impl-separation-techniques}

Although CPLEX already implements
the separation of some families of general cutting planes internally
(see \cref{sec:introduction-to-cplex}),
generating additional inequalities,
which aren't deducible from the static model,
can significantly improve the running time of the resolution process.
Cutting plane separation is a problem that involves finding (strong) violated inequalities
and embedding them inside a branch-and-cut framework.
Cutting planes improve the linear relaxation
by "cutting" fractional points from the convex hull of integer solutions.
An efficient cutting planes separation strategy
is probably the most important and delicate aspect of any branch-and-cut algorithm \parencite{ralphs2003}.
When evaluating the inclusion of a set of inequalities, it's critical to consider
the trade-off between the separation cost and the improvements in the linear relaxation.
Separation of integral inequalities, on the other hand,
can be viewed as a procedure for dynamically generating mandatory constraints
that would otherwise be impossible to insert statically into a MIP model.

Additional valid inequalities that are not strictly required to ensure the algorithm's correctness
but are computationally expensive to separate exactly,
may get included using a heuristic separation procedure.

The parametrization settings of the violated inequalities are another critical aspect
when implementing efficient cutting planes procedures.
The generation and number of cutting planes alone (without considering separation running time),
may significantly impact the BAC algorithm's computation time and memory consumption.
Sparse/compact inequalities are usually preferred whenever possible to reduce memory consumption.
When reporting violated inequalities to the MIP optimizer,
it is common practice to set a violation tolerance threshold
to limit the number of violated inequalities considered.
Inequalities that are not "sufficiently violated" aren't generated nor reported to the MIP optimizer.
A low violation threshold results in better dual bounds
and fewer branch nodes but slows down the convergence in each node.
On the other hand, a high violation threshold results in more branch nodes
but faster convergence speed in each node \parencite{jepsen2008branchandcut}.

Modern MIP optimizers, such as CPLEX,
can filter each user-provided cut by scoring them,
regardless of the violation threshold used by the separation procedure.
If CPLEX deems these cuts ineffective,
branching may occur prematurely regardless of the presence of violated inequalities (tailing off condition).
The process of scoring cuts necessitates even more computation time;
as a result, user-cuts filtering can be disabled if so desired.
However, if an effective tailing condition is required,
the user must implement it within the separation procedure of each cut.

In our implementation, all cutting planes reported to CPLEX are filtered.
The MIP optimizer itself makes the final decision on their inclusion.

\medskip

We are only interested in separating only the
GSECs \labelcref{eq:cptp-gsec-constraints},
RCC \labelcref{eq:cptp-rcc-inequality}
and GLM \labelcref{eq:cptp-glm-inequality}
families of inequalities in our branch-and-cut algorithm,
All these inequalities have one thing in common: they all require
the determination of a subset $S \subseteq V_0$.
A subset $S \subseteq V_0$ can be determined using a suitable \textit{labeling algorithm},
which partitions the network by assigning labels (integer) to each vertex.

The GSECs are the only constraints in our model that must be obligatorily
included by using an exact separation procedure.
Their inclusion must be devised at the very least for integral solutions of the IP model of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}.
GSECs can be precisely separated
by tracing the \textit{major connected components}
induced by the model's integral solution.

Tracing the connected components can be used to determine subsets
$T \subseteq V | \sum_{e \in \delta(T)} x_e = 0$,
which constitutes a valid labeling of the network.
However, the exact separation of fractional solutions is more complicated.
Let $x^\star \in \R^{|E|}$ denote the value of a fractional solution of
the linear relaxation in
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3},
the GSECs can be separated (exactly) by solving $(u, v)$-min-cuts
on a flow network where capacities are given from the fractional solutions' value $x^\star$.
The $(u, v)$-min-cuts outputs a subset $T \subseteq V$ induced from $(u, v)$ by
minimizing the term $\sum_{e \in \delta(T)} x^\star_e$.
The subset $T \subseteq V$ constitutes a valid labeling of the network for each $u, v \in V,\ u \ne v$.

Instead, the precise separation of the RCC and GLM inequalities
is a separate concern; for more info see in \cref{sec:cptp-rcc,sec:cptp-glm}.
There is currently
no exact separation procedure for the RCC inequalities  \parencite{jepsen2014}.
On the other hand, GLM inequalities can be separated by solving
$(u, v=0)$-min-cuts on a flow network with $u$-dependent capacities \parencite{letchford2006, jepsen2014}.

\medskip

In our implementation, we chose a different approach for the RCC and GLM inequalities
than the one proposed in \textcite{jepsen2014}.
We reuse the same labeling algorithm
employed for the exact fractional and integral separation of the GSECs inequalities.
The same two labeling algorithms are shared between the three inequalities' families.
Because the same labeling procedures feed the separation of three different families of inequalities,
we can limit the programming effort required to create custom separation procedures
while substantially reducing the computational impact.
The labeling algorithms and the cutting-plane separation procedures
were implemented in user-provided callbacks using the \textit{CPLEX generic callback API}.

\medskip

We will describe the labeling algorithm used for integral and fractional solutions
in the following two sections
\cref{sec:impl-labeling-integral-solutions,sec:impl-labeling-fractional-solutions}.
However, note that these two labeling algorithms
are only optimal for separating the GSECs inequalities,
and they behave suboptimally (heuristically) for separating the RCC and GLM inequalities.
In the remaining sections, instead,
we will be detailing the separation of each implemented inequality.

\subsection{Labeling from Integral Solutions}
\label{sec:impl-labeling-integral-solutions}

Our integral labeling algorithm
is devised to be optimal for detecting violated integral GSECs inequalities
of \cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5},
but the same procedure is shared
to feed a suboptimal integral separation also for the GLM and RCC inequalities,
as shown in the block diagram in \cref{fig:integral-separation-block-diagram}.

Let $x^\star \in \Set*{0, 1}^{|E|},\ y \in \Set*{0, 1}^{|V|}$ denote the
current integral solution of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}.
If $x^\star, y^\star$ violates a GSEC constraint,
it is simple to show that the solution contains at least a spurious unconnected sub-tour.
Sub-tours do not satisfy the original CPTP model of
\cref{eq:cptp-obj-function,eq:cptp-depot-part-of-tour-constraint,eq:cptp-resource-upper-bound-constraint,eq:cptp-flow-conservation-constraint,eq:cptp-gsec-constraints,eq:cptp-x-mip-var-bounds,eq:cptp-y-mip-var-bounds}
and should thus be removed.
Unconnected sub-tours can be detected
by computing the \textit{major connected components}
via a Depth-First Search (DFS) traversal
of the network induced from the integral solution's covered edges $\Set*{e \in E \mid x^\star_e = 1}$.

\medskip

More formally,
let $C = \Set*{-1, 0, \dots, n_c - 1}$ denote the set of connected components
resulting from the integral solution $x^\star \in \Set*{0, 1}^{|E|},\ y \in \Set*{0, 1}^{|V|}$.
A vertex $i \in V$ is said to belong to a singleton connected component,
if the connected component contains only $i$ itself, namely $y^\star_i = 0$.
We are only interested in modeling \textbf{major} connected components,
whith have at least two vertices.
We ignore singleton connected components
and use the sentinel value $-1$ to encode all the vertices $i \in V$ belonging to singletons.
As a result, the number $n_c \in \Z$ frankly represents the number
of major connected components that satisfies $n_c \ge 1$.
Equivalently,
$n_c$ represents the number of sub-tours formed in the current integral solution.
Let $cc(i) \in C$ be an array
that encodes in which connected component each vertex $i \in V$ belongs.
Because the depot node always belongs to a connected component, we fix $cc(0) = 0$ by definition.
Instead, for singletons we fix $cc(i) = -1  \quad \forall i \in V_0 \mid y^\star_i = 0$.
The connected components can be computed
by a simple DFS traversal which pseudocode is provided in \cref{algo:cc-dfs}.

Consider the sets $T_k = \Set*{i \in V \mid cc(i) = k}$ with $k = 0, \dots, n_c$
computed from the recently devised labeling algorithm \labelcref{algo:cc-dfs}.
Due to the construction of such sets,
by letting $k = 0, \dots, n_c$,
it holds that:
$|T_k| \ge 2$,
$\sum_{e \in \delta(T_k)} x^\star_e = 0$
and $\exists i \in T_k \mid y^\star_i = 1$,
thus ensuring the correctness of the entire branch-and-cut procedure.

\begin{figure}[ht]
	\centering
	\framebox{\includegraphics[width=6cm]{Imgs/integral-separation-block-diagram.cropped.pdf}}
	\caption{
		A block diagram illustrating the structure
		of the employed separation for integral solutions along with the shared labeling algorithm.
	}
	\label{fig:integral-separation-block-diagram}
\end{figure}

\begin{algorithm}
	\caption{An algorithm for computing the major connected components through a Depth-First Search (DFS) traversal}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\KwResult{$n_c$: number of subtours formed}
	\KwResult{$cc[i] \in C$: connected component of $\forall i \in V$}
	\input{Content/Chapters/Snippets/cc-dfs-pseudoalgo.tex}
	\label{algo:cc-dfs}
\end{algorithm}

\subsection{Labeling from Fractional Solutions}
\label{sec:impl-labeling-fractional-solutions}

Our fractional labeling algorithm is devised to be optimal for
detecting violated fractional GSECs inequalities
of \cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3},
but the same procedure is shared
to feed a suboptimal fractional separation also for the GLM and RCC inequalities,
as shown in the block diagram in \cref{fig:fractional-separation-block-diagram}.
This algorithm is inherently more difficult, and computationally expensive
than the integral labeling algorithm.

A valid set $T \subseteq V$ can be separated for a fractional $x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$,
by solving a
maxflow problem between two arbitrary source and sink vertices $u, v \in V,\ u \ne v$ on a fully connected directed graph.
The maxflow problem is represented by a directed symmetric flow network,
where the capacities $w_{ij} \in \R \quad \forall i, j \in V$
are derived from the current fractional solution $w_{ij} = x^\star_{\Set*{i, j}} \quad \forall i, j \in V$.

A solution to the maxflow problem
produces a maxflow $\maxflow(u, v)$ and a bipartition, also known as \textit{"binary coloring"},
of the set $V$,
namely two complementary sets $F_1(u, v),\ F_2(u, v)$
such that $F_1(u, v) \cup F_2(u, v) = V$, $F_1 \cap F_2 = \emptyset$ and $u \in F_1(u, v),\ t \in F_2(u, v)$.
The quantity $\deltaplus(F_1(u, v))$ constitutes the min-cut induced from solving the maxflow problem over $(u, v)$.
It is well understood that solving a maxflow problem assures the following two properties:
\begin{enumerate}
	\item Arcs $\{ (i, j) \mid i \in F_1(u, v),\ j \in F_2(u, v) \}$ are saturated
	\item Arcs $\{ (j, i) \mid i \in F_1(u, v),\ j \in F_2(u, v) \}$ are drained.
\end{enumerate}
As a result, the following statements holds:
\begin{align}
	\sum_{(i, j) \in \deltaplus(F_1(u, v))} f_{ij}  & = \sum_{(i, j) \in \deltaplus(F_1(u, v))} x^\star_{\Set*{i, j}} & = \maxflow(u, v) \\
	\sum_{(i, j) \in \deltaminus(F_1(u, v))} f_{ij} & = \sum_{(i, j) \in \deltaplus(F_2(u, v))} f_{ij}                & = 0,
\end{align}
where $f_{ij}$ denotes the flow in the corresponding arc $(i, j),\ i, j \in V$ of the flow network.

Because we are dealing with a \textbf{symmetrical} flow network,
solving the maxflow problem between pairs $(u, v)$ and pair $(u, v)$
will yield the same maxflow value,
i.e. $\maxflow(u, v) = \maxflow(v, u)$.
However, the induced bipartitions are not guaranteed to be symmetric in the general case.
In general, we have that $F_1(u, v) \ne F_2(v, u)$ and $F_2(u, v) \ne F_1(v, u)$.
To demonstrate this, consider the following simple flow network:
\begin{center}
	\begin{tikzpicture}[node distance={20mm}, main/.style = {draw, circle, fill=black!10!white}]
		\centering

		\node[main] (0) {$0$};
		\node[main] (1) [right of = 0] {$1$};
		\node[main] (2) [right of = 1] {$2$};
		\node[main] (3) [right of = 2] {$3$};
		\node[main] (4) [right of = 3] {$4$};

		\draw (0) -- (1) node [midway, yshift=2mm] {$0$};
		\draw (1) --  (2) node [midway, yshift=2mm] {$10$};
		\draw (2) --  (3) node [midway, yshift=2mm] {$10$};
		\draw (3) --  (4) node [midway, yshift=2mm] {$0$};
	\end{tikzpicture},
\end{center}
produces the same maxflow value when solving for $(0, 4)$ and $(4, 0)$ pairs
and produces $F_1(0, 4) = \{ 0\},\ F_2(0, 4) = \{ 1, 2, 3, 4\}$, $F_1(4, 0) = \{ 4 \},\ F_2(4, 0) = \{ 0, 1, 2, 3\}$,
clearly indicating a nonsymmetric coloring.
This behavior is a direct consequence of the fact that flow networks do not guarantee unique min-cuts.

\medskip

We used the push relabel max flow algorithm first developed in \cite{goldberg1997} in this thesis.
The push relabel algorithm,
takes $O(N^4)$ time to complete and, in practice,
is typically faster than commoner approaches like the Ford-Fulkerson algorithm.
When combined with an exhaustive enumeration of all possible $u, v \in V,\ u \ne v$ choices,
the Goldberg's algorithm can take up to $O(N^6)$ time.

The Gomory-Hu tree, first presented in \cite{gomory1961},
allows us to compute all pairs of $(u, v)$ max flows with only $N$ main maxflow computations.
A Gomory-Hu tree, in essence, is a data structure that represents a simpler reduced flow network
in which maxflow computations become trivially solvable
with a single iteration of the Ford-Fulkerson algorithm in $\Theta(N^2)$.
An exhaustive enumeration of all possible $(u, v)$ pairs using the Gomory-Hu tree
and the Goldberg's algorithm takes up to $O(N^5)$ time to build the tree
and further $\Theta(N^4)$ to query for all the possible $F_1(u, v), F_2(u, v)$ bipartitions.

We used the Gomory-Hu tree in our implementation to thoroughly enumerate all possible $(u, v)$ max flows.
For the sake of brevity, we will not include the pseudocode for the maxflow and Gomory-Hu tree algorithms.
For their respective implementations,
please see the \urlref{https://github.com/dparo/master-thesis}{Github repository}.

\medskip

We conclude the section with suggestion for implementing reliable maxflow algorithms.
Because of the accumulation of accuracy errors,
implementing fast and correct maxflow algorithms
that operate directly with floating-point arithmetic can be very problematic.
Any trivial implementation can "get stuck" in massively long loops
pushing atomically small amounts of flows.
Special care must be taken when developing this kind of algorithm.
Unit testing and other solid software engineering practices
can aid in identifying problematic implementations.

A cleaner approach is to implement a maxflow algorithm that uses integer arithmetic.
Because $x^\star$ is bounded in the $[0, 1]$ range,
we can multiply the fractional solution value $x^\star$ by a big-constant $M \in \R_{+}$ (e.g. $M = 10^6$)
and truncate its value when defining the capacities of the flow network.
After that, the value $\maxflow(u, v)$ must be remapped on the original scale by dividing it by $M$.
Our maxflow implementation follows the latter approach: it uses integer arithmetic
for simplicity and stability.

\begin{figure}[ht]
	\centering
	\framebox{\includegraphics[width=8cm]{Imgs/fractional-separation-block-diagram.cropped.pdf}}
	\caption{
		A block diagram illustrating the structure
		of the employed separation for fractional solutions along with the shared labeling algorithm.
	}
	\label{fig:fractional-separation-block-diagram}
\end{figure}

\subsection{GSEC Separation}
\label{sec:impl-gsec-separation}

\subsubsection{GSEC Integral Separation}
\label{sec:impl-gsec-integral-separation}

The GSEC integral separation procedure is the most important
separation procedure in our implementation,
since it is mandatory to ensure the correctness of the branch-and-cut algorithm.
GSECs inequalities which are violated by integral solutions
must be separated exactly and reported as is
(without employing violation thresholds) to the MIP optimizer.

The GSEC inequalities require for the identification of a subset $S \subseteq V_0,\ |S| \ge 2$.
Let $T_k  = \Set*{i \in V \mid cc(i) = k},\ |T_k| \ge 2 \quad \forall k \in \Set*{1, \dots, n_c}$ be the labeling
outputted from the major connected components as discussed in \cref{sec:impl-labeling-integral-solutions}.
By construction $n_c \ge 1,\ 0 \in T_0$.
Then a valid subset $S \subseteq V_0$ can be picked as $S = T_k \quad \forall k \in \Set*{1, \dots, n_c}$.
Which implies that,
any major connected component (i.e. sub-tour) that does not contain the depot node,
can be used as a valid set $S \subseteq V_0$ for separating GSEC inequalities from integral solutions.
If $n_c = 1$ then no $S \subseteq V_0$ can be separated,
which implies that the current integral solution models an optimal solution for the whole CPTP formulation
\labelcref{eq:cptp-obj-function,eq:cptp-depot-part-of-tour-constraint,eq:cptp-resource-upper-bound-constraint,eq:cptp-flow-conservation-constraint,eq:cptp-gsec-constraints,eq:cptp-x-mip-var-bounds,eq:cptp-y-mip-var-bounds}.

Let $x^\star \in \Set*{0, 1}^{|E|},\ y \in \Set*{0, 1}^{|V|}$ denote the
current integral solution of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}.
Recall the GSEC inequality definition in \cref{eq:cptp-gsec-constraints},
it is easy to verify that
$\sum_{e \in \delta(S)} x^\star_{e} = 0$, $y_i =  1 \quad \forall i \in S$
which implies that \cref{eq:cptp-gsec-constraints} cannot be satisfied by any $i \in S$.

\medskip

In a single integral separation iteration we can therefore separate:
\begin{equation}
	\sum^{n_c}_{k = 1} \SetSize*{ \Set*{ i \mid cc(i) = k \quad \forall i \in V } }
\end{equation}
violated GSECs inequality, which can be promptly reported to the MIP solver to reject the candidate integral solution.

A complete pseudocode of the GSEC integral separation procedure is provided in \cref{algo:gsec-integral-sep}.

\begin{algorithm}
	\caption{An algorithm for separating GSEC integral inequalities for the CPTP}
	\label{algo:gsec-integral-sep}
	\KwResult{$n_c$: number of major connected components}
	\KwData{$cc[i] \in C$: connected component $\forall i \in V$, see \cref{sec:impl-labeling-integral-solutions}}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\input{Content/Chapters/Snippets/gsec-integral-sep-pseudoalgo.tex}
\end{algorithm}

\subsubsection{GSEC Fractional Separation}
\label{sec:impl-gsec-fractional-separation}

The separation of GSEC inequalities for fractional solutions,
while it is non-strictly required for our implementation,
can dramatically reduce the number of branch nodes.

Let $\maxflow(u, v),\ F_1(u, v),\ F_2(u, v)$ denote the maxflow value and bipartitions
produced from the labeling algorithm described in \cref{sec:impl-labeling-fractional-solutions}.
A valid $S \subseteq V_0, |S| \ge 2$ for separating GSEC inequalities from fractional solution can be picked such that:
\begin{equation}
	S \subseteq V_0 =
	\begin{cases}
		F_1(u, v), & \texttt{if } 0 \notin F_1(u, v) \\
		F_2(u, v), & \texttt{otherwise}
	\end{cases},
	\qquad
	|S| \ge 2.
\end{equation}
Such approach can feed up to
$N^2 - N$ different sets $S \subseteq V_0$,
one for each possible pair $\Tuple*{u, v} \in V^2,\ u \ne v$

Let $x^\star \in \R^{|E|},\ y \in \R^{|V|}$ denote the
current fractional solution of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}.
Recall the GSEC inequality definition in \cref{eq:cptp-gsec-constraints},
it is easy to verify that $\sum_{e \in \delta(S)} x^\star_{ij} = \maxflow(u, v)$
holds due to the symmetry property of the flow network.

Therefore, any $i \in S$ that violates $\maxflow(u, v) \ge 2 y_i$
can be used to separate a violated GSEC inequality.
With such approach t is possible to separate $O(N^3)$ GSECs per fractional solution.
We noticed, through a quick empirical evaluation, that
generating and reporting all the encountered violated GSECs inequalities
led to a slow-down of the MIP optimizer.

\medskip
In our implementation we opted for a different approach by relaxing the conditions at which these cuts are reported.
For each subset $S \subseteq V_0,\ |S| \ge 2$, we report only the single most violated GSEC
associated to the customer $i \in V_0$ that maximizes the $\maxflow(u, v) - 2 y_i$ violation.
On top of that, to limit the number of weak GSEC inequalities that are reported to the MIP optimizer,
we define a violation threshold $\varepsilon_{\mt{GSEC}}$ and report the associated cut only if:
\begin{equation}
	\maxflow(u, v) \ge 2 y_i - \varepsilon_{\mt{GSEC}}
\end{equation}
is violated.
In our implementation we picked $\varepsilon_{\mt{GSEC}} = \epsGsecFValue$.

A complete pseudocode of the GSEC fractional separation procedure is provided in \cref{algo:gsec-frac-sep}.

\begin{algorithm}
	\caption{An algorithm for separating GSEC fractional inequalities for the CPTP}
	\label{algo:gsec-frac-sep}
	\KwData{$\maxflow(u, v), F_1(u, v), F_2(u, v)$: maxflow and bipartitions induced from $(u, t)$-min-cut, see \cref{sec:impl-labeling-fractional-solutions}}
	\KwData{$x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$: current fractional solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}
	}
	\input{Content/Chapters/Snippets/gsec-frac-sep-pseudoalgo.tex}
\end{algorithm}

\subsection{RCC separation}
\label{sec:impl-rcc-separation}

The RCC inequalities, defined in \cref{eq:cptp-rcc-inequality},
require for the identification of a subset $S \subseteq V_0, |S| \ge 1$.
Such inequalities can be rewritten in the following form:
\begin{equation}
	\ExprCptpFlowExiting{S} - \ExprCptpServedDemandWithWeight{S}{i}{\frac{2 q_i}{\ExprQr(S)}}    \ge   2 \left( \ceil*{ \frac{q(S)}{Q}} - \frac{q(S)}{Q_{\mathrm{R}}(S)} \right) \quad \forall S \subseteq V_0,\ |S| \ge 1.
\end{equation}

We first describe the separation of the RCC inequalities for integral solutions.
Such separation procedure follows roughly the same reasoning
employed for the GSEC integral separation discussed in \cref{sec:impl-gsec-integral-separation}.
Namely, let $T_k  = \Set*{i \in V \mid cc(i) = k},\ |T_k| \ge 2 \quad \forall k \in \Set*{1, \dots, n_c}$ be the labeling
outputted from the major connected components as discussed in \cref{sec:impl-labeling-integral-solutions}.
Then a valid subset $S \subseteq V_0,\ |S| \ge 1$ can be picked as $S = T_k \quad \forall k \in \Set*{1, \dots, n_c}$.
After picking the appropriate subset $S$ we test for the violation of the inequality.
Only if the associated RCC inequality is violated it is reported to the MIP optimizer.
A complete pseudocode is provided in \cref{algo:rcc-integral-sep}.

Next we describe the separation of the RCC inequalities for fractional solutions.
Such separation procedure also follows roughly the same reasoning
for the GSEC fractional separation discussed in \cref{sec:impl-gsec-fractional-separation}.
Let $\maxflow(u, v),\ F_1(u, v),\ F_2(u, v)$ denote the maxflow value and bipartitions
produced from the labeling algorithm described in \cref{sec:impl-labeling-fractional-solutions}.
A valid $S \subseteq V_0, |S| \ge 2$ for separating RCC inequalities
from fractional solution can be picked such that:
\begin{equation}
	S \subseteq V_0 =
	\begin{cases}
		F_1(u, v), & \texttt{if } 0 \notin F_1(u, v) \\
		F_2(u, v), & \texttt{otherwise}
	\end{cases}.
\end{equation}
After picking the appropriate subset $S$ we test for violation of the inequality,
but as is the case for fractional separation,
we employ a non-zero violation threshold $\varepsilon_{\mt{RCC}}$.
In our implementation we set $\varepsilon_{\mt{RCC}} = \epsRccFValue$.
With such an approach we can separate $O(N^2)$ RCCs per fractional solution.
A complete pseudocode is provided in \cref{algo:rcc-frac-sep}.

\begin{algorithm}
	\caption{An algorithm for separating RCC integral inequalities for the CPTP}
	\label{algo:rcc-integral-sep}
	\KwResult{$n_c$: number of major connected components}
	\KwData{$cc[i] \in C$: connected component $\forall i \in V$, see \cref{sec:impl-labeling-integral-solutions}}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\input{Content/Chapters/Snippets/rcc-integral-sep-pseudoalgo.tex}
\end{algorithm}

\begin{algorithm}
	\caption{An algorithm for separating RCC fractional inequalities for the CPTP}
	\label{algo:rcc-frac-sep}
	\KwData{$\maxflow(u, v), F_1(u, v), F_2(u, v)$: maxflow and bipartitions induced from $(u, t)$-min-cut, see \cref{sec:impl-labeling-fractional-solutions}}
	\KwData{$x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$: current fractional solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}
	}
	\input{Content/Chapters/Snippets/rcc-frac-sep-pseudoalgo.tex}
\end{algorithm}

\subsection{GLM separation}
\label{sec:impl-glm-separation}

The GLM inequalities, defined in \cref{eq:cptp-glm-inequality},
require for the identification of a subset $S \subseteq V_0, |S| \ge 2$.
Such inequalities can be rewritten in the following form:
\begin{equation}
	\sum\limits_{
		\EqStackTwo{e = \Set*{i,j} \in \delta(S)}{i \in S,\ j \notin S}
	} x_e \Expr*{1 - 2 \frac{q_j}{Q}}
	- \sum\limits_{i \in S} \frac{2 q_i}{Q} y_i
	\ge 0 \quad \forall S \subseteq V_0,\ |S| \ge 2
	.
\end{equation}

We first describe the separation of the GLM inequalities for integral solutions.
Such separation procedure follows roughly the same reasoning
employed for the GSEC integral separation discussed in \cref{sec:impl-gsec-integral-separation}.
Namely, let $T_k  = \Set*{i \in V \mid cc(i) = k},\ |T_k| \ge 2 \quad \forall k \in \Set*{1, \dots, n_c}$ be the labeling
outputted from the major connected components as discussed in \cref{sec:impl-labeling-integral-solutions}.
Then a valid subset $S \subseteq V_0,\ |S| \ge 2$ can be picked as $S = T_k \quad \forall k \in \Set*{1, \dots, n_c}$.
After picking the appropriate subset $S$ we test for the violation of the inequality.
Only if the associated GLM inequality is violated it is reported to the MIP optimizer.
A complete pseudocode is provided in \cref{algo:glm-integral-sep}.

Next we describe the separation of the GLM inequalities for fractional solutions.
Such separation procedure also follows roughly the same reasoning
for the GSEC fractional separation discussed in \cref{sec:impl-gsec-fractional-separation}.
Let $\maxflow(u, v),\ F_1(u, v),\ F_2(u, v)$ denote the maxflow value and bipartitions
produced from the labeling algorithm described in \cref{sec:impl-labeling-fractional-solutions}.
A valid $S \subseteq V_0, |S| \ge 2$ for separating GLM inequalities
from fractional solution can be picked such that:
\begin{equation}
	S \subseteq V_0 =
	\begin{cases}
		F_1(u, v), & \texttt{if } 0 \notin F_1(u, v) \\
		F_2(u, v), & \texttt{otherwise}
	\end{cases},
	\qquad
	|S| \ge 2.
\end{equation}
After picking the appropriate subset $S$ we test for violation of the inequality,
but as is the case for fractional separation,
we employ a non-zero violation threshold $\varepsilon_{\mt{GLM}}$.
In our implementation we set $\varepsilon_{\mt{GLM}} = \epsGlmFValue$.
With such an approach we can separate $O(N^2)$ GLMs per fractional solution.
A complete pseudocode is provided in \cref{algo:glm-frac-sep}.

\begin{algorithm}
	\caption{An algorithm for separating GLM integral inequalities for the CPTP}
	\label{algo:glm-integral-sep}
	\KwResult{$n_c$: number of major connected components}
	\KwData{$cc[i] \in C$: connected component $\forall i \in V$, see \cref{sec:impl-labeling-integral-solutions}}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\input{Content/Chapters/Snippets/glm-integral-sep-pseudoalgo.tex}
\end{algorithm}

\begin{algorithm}
	\caption{An algorithm for separating GLM fractional inequalities for the CPTP}
	\label{algo:glm-frac-sep}
	\KwData{$\maxflow(u, v), F_1(u, v), F_2(u, v)$: maxflow and bipartitions induced from an arbitrary $s \ne t, s \in V, t \in V$ pair}
	\KwData{$x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$: current fractional solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}
	}
	\input{Content/Chapters/Snippets/glm-frac-sep-pseudoalgo.tex}
\end{algorithm}
