\chapter{Implementation}
\label{sec:implementation-chapter}

This chapter introduces the proposed branch-and-cut algorithm (BAC).
The BAC algorithm was implemented using the recent \textit{CPLEX 22.1 C callable library}.
\textit{CPLEX version 22.1} was released in March 2022.
The proposed branch-and-cut uses the CPTP formulation as the foundational static IP model.
Refer to the previous discussion on the CPTP in \cref{sec:the-capacitated-profitable-tour-problem} for more information.
By appropriately defining the profit function associated with each vertex $p_i \quad \forall i \in V$,
our framework can be utilized as a pricer inside a column generation approach for the standard CVRP.
The BAC's source code was developed in \textit{C}.
The source code is freely available under a permissive \texttt{MIT license}
at the following \textit{Github} repository: \url{https://github.com/dparo/master-thesis}.

\medskip

\urlref{https://www.ibm.com/analytics/cplex-optimizer}{IBM ILOG CPLEX Optimizer},
CPLEX for short,
is a commercial optimization software package for solving problems expressed as either:
linear programs, mixed-integer programs, quadratic programs, or quadratically constrained programs.
For an introduction to CPLEX refer to \cref{sec:introduction-to-cplex}.

The CPLEX optimizer is heavily used in our branch-and-cut implementation
to solve the associated CPTP MIP model.
The cutting planes separation was implemented using \textit{CPLEX generic callback functions},
which has the advantage of not disabling the \textit{Dynamic Search algorithm}.
The \textit{Dynamic Search} is the CPLEX's internal advanced proprietary branch-and-cut algorithm,
as discussed in \cref{sec:introduction-to-cplex}.

Using a modern MIP solver, such as CPLEX, may provide at least two advantages
over tailored pricer algorithms, such as the labeling algorithm \parencite{desrochers1992, feillet2004}:
(i) parallelization and efficient use of the machine's multiple cores basically for free,
(ii) take advantage of all the engineering effort that went into creating an efficient MIP solver
(preprocessing, diving, fixing, primal heuristics, and more).
However, there are drawbacks to such an approach.
Complicated relaxations or constraints, such as the ng-sets \parencite{baldacci2011},
may be impractical to implement efficiently within a BAC algorithm.

\medskip

This chapter's outline is quickly summarized.
The implemented static IP model is presented in \cref{sec:impl-full-static-model}.
\Cref{sec:impl-warm-starting} describes the implemented primal heuristics for \textit{warm starting} the MIP optimizer.
\Cref{sec:impl-branching} discusses the implemented branching scheme.
Finally, \cref{sec:impl-separation-techniques} describes the cutting planes strategies used, including a discussion of the separation techniques used.

\section{Full static model}
\label{sec:impl-full-static-model}

Our static IP model is based on a minor modification of the CPTP formulation
\labelcref{eq:cptp-obj-function,eq:cptp-depot-part-of-tour-constraint,eq:cptp-resource-upper-bound-constraint,eq:cptp-flow-conservation-constraint,eq:cptp-gsec-constraints,eq:cptp-x-mip-var-bounds,eq:cptp-y-mip-var-bounds}
by disregarding the GSECs inequalities \labelcref{eq:cptp-gsec-constraints}.
Upon violation,
the GSECs will be exactly separated lazily to ensure the approach's correctness.

We've implemented the following static Integer Programme (IP) model:
\begin{align}
	\min_{x,y} \quad z_\mt{CPTP}(x, y) & = \ExprCptpObjValDef                     & \label{eq:cptp-static-model-0}                         \\
	                                   & y_0 = 1                                  & \label{eq:cptp-static-model-1}                         \\
	                                   & B \le   \ExprCptpDemandSum   \le Q       & \label{eq:cptp-static-model-2}                         \\
	                                   & \ExprCptpEdgesIncident{i}    = 2 y_i     & \quad \forall i \in V  \label{eq:cptp-static-model-3}  \\
	                                   & x_{e}                   \in \Set*{0, 1}  & \quad \forall e \in E  \label{eq:cptp-static-model-4}  \\
	                                   & y_{i}                    \in \Set*{0, 1} & \quad \forall i \in V  \label{eq:cptp-static-model-5},
\end{align}
where
$B \in R_+$ is an additional lower bound on the resource consumption
that may help in gaining a slight improvement on the linear relaxation.
The value of $B$ is computed as $B = q_u + q_v$, where $u, v \in V_0,\ u \ne v$
represent the least two demanding customers in the network:
$q_u \le q_v \le q_i \quad \forall i \in V_0, i \ne u, v$.

\subsection{Upper cutoff value}
\label{sec:impl-upper-cutoff-value}

In the context of CVRP pricing, we're only interested in routes achieving a strictly negative cost function.
A MIP optimizer can use the \textit{upper cutoff value} to reduce the number of evaluated branch-and-bound nodes.
The upper cutoff value acts as a direct constraint on the objective function:
\begin{equation}
	z_\mt{CPTP}(x, y) \le 0 - \varepsilon_{\mt{ct}},
\end{equation}
where $\varepsilon_{\mt{ct}} \in \R_+$ denotes the upper cutoff tolerance.
Most MIP solvers, including CPLEX, has internal support for specifying cutoff values.
However, fixing the cutoff value is not the same as specifying an explicit constraint in the static model.
Only when the branch-and-bound procedure is invoked, do cutoff values contribute.
An explicit constraint, on the other hand, contributes even at the linear relaxation level.
The upper cutoff tolerance $\varepsilon_{\mt{ct}}$ biases the threshold at which a produced route
can be considered a valid reduced cost column.
A non-zero value for $\varepsilon_{\mt{ct}}$ avoids numerical
stability problems caused by the usage of floating-point arithmetic
employed in BPC implementations.

To ensure correctness, the value of $\varepsilon_{\mt{ct}}$ must match the value used by the BPC algorithm.
In our case, we chose $\varepsilon_{\mt{ct}} = 10^{-6}$ because it is the value used by the modern BPC framework described in \textcite{sadykov2021}.

\section{Warm Starting}
\label{sec:impl-warm-starting}

\textit{Warm starting} is a technique that involves feeding
a MIP optimizer with (good) feasible solutions
before beginning the resolution process.
Having a set of (good) initial feasible solutions
can significantly reduce the primal-dual bound gap,
as a result, the amount of time required to achieve optimality.
Warm starting can be applied to a wide range of IP problem domains,
and it is usually supported by the market's leading MIP solvers,
such as CPLEX.

Primal heuristics offer a quick and practical approach to warm starting.
A CPTP problem is very similar to a TSP problem.
As a result, TSP's heuristics are fine-tunable to work successfully even with the CPTP.
Many contributions were dedicated to researching good heuristics for the TSP,
see \cite{rosenkrantz1977, johnson1997, laporte1992, johnson2007, hoffman2013}.

\medskip

The warm starting procedure that we've implemented is explained in the remainder of this section.
The procedure is divided into two stages:
a constructive insertion heuristic stage (see \cref{sec:impl-insertion-heuristic})
followed by a 2-OPT refinement stage (see \cref{sec:impl-2opt-refinement}),

\subsection{Insertion heuristic}
\label{sec:impl-insertion-heuristic}

\cite{rosenkrantz1977} do an excellent job of describing the TSP's insertion heuristic algorithm
and various facets in which it can be implemented.
In $\Theta(N^2)$ time, the insertion heuristic algorithm can generate a new feasible primal solution.
In this section,
we modify the TSP insertion heuristic
to make it work with the CPTP.

\medskip

Start by selecting two distinct nodes $u, v \in V,\ q_u + q_v \le Q$
to form an initial tour back-to-back $p = \Tuple*{u, v}$.

The insertion heuristic algorithm is an iterative approach
in which an almost-feasible CPTP tour is available at each iteration.
If the CPTP admits feasible solutions,
the final available tour will undoubtedly be feasible
when all iterations of the insertion heuristic are exhausted.
Let's define $q(p) \le Q$ as the total demand served
by the partial route in this iteration.
Choose a vertex $a \in p$ and a vertex $h \notin p$ for each iteration.
Let's define $b$ as the successor of node $a$ in the current tour.
The goal is to insert $h$ in the tour
by deleting edge $\Tuple*{a, b}$
and inserting edges $\Tuple*{a, h},\ \Tuple*{h, b}$.
Only perform the insertion operation if the $h$ insertion
is required to restore feasibility or if its insertion lowers the route cost.
Let us define the extra mileage more formally as follows:
\begin{equation}
	\Delta_m(h, a) =
	\begin{cases}
		c_{ah} + c_{hb} - c_{ab} - p_h, & \texttt{if } q(p) + q_h \le Q \\
		\infty,                         & \texttt{otherwise},
	\end{cases}
\end{equation}
which represents the delta route cost in inserting $h$ as the successor of node $a$.
A vertex $h \in V$ is a good candidate for insertion
if at least one of the following conditions is met:
\begin{enumerate}
	\item $\Delta_m(h, a) < 0$, i.e. inserting $h$ improves over the current route.
	\item $h = 0$, i.e. $h$ is the depot node.
	      When the insertion candidate coincides with the depot,
	      regardless of whether its insertion is convenient, it must occur sooner or later.
	      Because we have defined $q_0 = 0$ by convention,
	      $q(p) + q_0 \le Q$ is always satisfied for the depot node.
	\item The number of visited nodes in the current tour is $2$ and $q(p) + q_h \le Q$.
\end{enumerate}

Prior to insertion the partial route has the form $p = \Tuple*{\dots, a, b, \dots}$;
whereas after the insertion operation completes: $p = \Tuple*{\dots, a, h, b, \dots}$.
In our implementation we employed the \textit{cheapest insertion scheme},
which means that the pair $(h, a)$ is chosen to minimize the extra mileage $\Delta_m(h, a)$
across all possible choices for $a \in p,\ h \notin p$.
When there are no further $h$ candidate vertices can be found, the algorithm stops.
At the end of the insertion heuristic, $p$ is a valid route that visits the depot node.
The depot node may not necessarily be the first element of the tour: $p_0 \ne 0$.
A simple circular rotation is all that is required to restore the condition $p_0 = 0$.
If no valid $h$ candidate can be found while the tour length is $2$,
we can conclude that the CPTP formulation does not admit any feasible solution
before even solving the IP formulation.

In our implementation we chose $u = 0$ and $v \in V_0$ so that $q_u + q_v \le Q$.
This approach allows us to generate $O(N)$ acceptable feasible primal solutions in $O(N^3)$ time.

\subsection{2-OPT refinement}
\label{sec:impl-2opt-refinement}

Each solution produced from the insertion heuristic
can be further improved using a \textit{2-OPT refinement procedure}.
The 2-OPT algorithm is a heuristic local-search hill-climbing procedure
proposed originally for the TSP in \textcite{flood1956, croes1958} independently.

The 2-OPT algorithm works iteratively in $\Omega(N^2)$ number of iterations.
Unfortunately,
as \textcite{chandra1999} points out,
the 2-OPT procedure may take an exponential number of iterations
when fed with purposefully artificially constructed instances.
Although this is unfortunate, it is also worth noting that in practice.
The probabilistic average number of iterations required for 2-OPT is at most polynomial.

Each iteration of the 2-OPT procedure looks for an existing edge crossing and, if found,
performs a 2-OPT exchange to undo it.
A 2-OPT exchange is a \textit{primal operation},
which means that its use preserves route feasibility.
Because 2-OPT exchange does not add nor remove vertices from the current route $p$,
the route's gained profit does not change during
the 2-OPT procedure's execution time.
As a result, adapting the original TSP's 2-OPT procedure to the CPTP problem becomes trivial.

Let $a, b \in p$ represent two vertices visited along the current route $p$.
Let $a^\prime, b^\prime \in p$ denote respectively the successor of $a$ and $b$ in the current route $p$.
A 2-OPT exchange replaces edges $(a, a^\prime)$, $(b, b^\prime)$
with $(a, b)$, $(a^\prime, b^\prime)$
but only if the delta distance, defined as:
\begin{equation}
	\Delta(a, b) = c_{a b} + c_{a^\prime b^\prime} - c_{a a^\prime} - c_{b b^\prime},
\end{equation}
satisfies $\Delta(a, b) < 0$.
In this case, a 2-OPT exchange over vertices $(a, b)$ reduces the route cost.
Following a 2-OPT exchange, the portion of the route $[a_s, \dots, b]$
denoted by head $a_s$ and tail $b$ must be reversed.

In our implementation
we look for vertices $a, b$ achieving the cheapest exchange,
that is, the delta distance $\Delta(a, b)$ is minimized
across all possible valid choices of $a, b \in p$.
The local search algorithms terminates when $\nexists (a, b) \mid a, b \in p,\ \Delta(a, b) < 0$.

\section{Branching}
\label{sec:impl-branching}

We don't implement any specific branching schemes.
We rely on the branching schemes already provided by the CPLEX MIP optimizer.

\section{Cutting planes and Inequalities separation}
\label{sec:impl-separation-techniques}

Despite CPLEX already implements internally
the separation of some families of general cutting planes
(see \cref{sec:introduction-to-cplex}),
generating additional inequalities,
which cannot be deduced from the static model,
can drastically improve the running time of the resolution process.
Cutting planes separation is a problem which consists
in finding (strong) violated inequalities
so that they can be embedded inside a branch-and-cut framework.
Cutting planes improve the linear relaxation
by "cutting" fractional points from the convex-hull of integer solutions.
An effective cutting planes separation strategy
is probably the most important and delicate aspect of any branch-and-cut algorithm \parencite{ralphs2003}.
When evaluating the inclusion of a set of inequalities,
considering the trade-off between the separation cost
and the improvements in the linear relaxation
is a factor of fundamental importance.
Integral inequalities' separation, instead, can be seen as a procedure
to dynamically generate mandatory constraints
that would otherwise be impossible to insert statically into a MIP model.

Additional valid inequalities which are non-strictly necessary to guarantee the algorithm's correctness,
but are computationally expensive to separate exactly,
may be included through a heuristic separation procedure.

Another important factor to take into consideration when implementing
efficient cutting planes procedures lies in the parametrization settings
of the violated inequalities.
The generation and number of cutting planes alone (without considering the separation running time),
can highly influence both the computation time and memory consumption of the BAC algorithm.
In order to reduce memory consumption, sparse/compact inequalities are usually preferred whenever possible.
When reporting violated inequalities to the MIP optimizer,
it is usually good practice to define a violation tolerance threshold,
to limit the number of violated inequalities taken into consideration.
Namely, inequalities which are not "sufficiently violated" aren't generated nor reported
to the MIP optimizer.
A low violation threshold results in better dual bounds and fewer branch nodes,
but may slower the convergence in each node.
In the opposite way, a high violation threshold results in more branch nodes,
but faster convergence speed in each node \parencite{jepsen2008branchandcut}.

Modern MIP optimizers, such as CPLEX, regardless of the violation threshold
employed by the separation procedure,
can filter each user-provided cuts by scoring them.
Premature branching may occur, regardless of the existence of violated inequalities,
if CPLEX deems these cuts ineffective (tailing off condition).
Scoring cuts costs even more computation time,
for this reason,
it is possible to disable user-cuts filtering.
However, in such case if an effective tailing condition is required,
it must be implemented by the user inside the separation procedure.

In our implementation, all cutting planes reported to CPLEX are subject to filtering
and the ultimate choice of whether to include the generated cutting planes is left to the MIP optimizer.

\medskip

In our branch-and-cut algorithm,
we are concerned in separating only the
GSECs \labelcref{eq:cptp-gsec-constraints},
RCC \labelcref{eq:cptp-rcc-inequality}
and GLM \labelcref{eq:cptp-glm-inequality}
families of inequalities.
All these inequalities share something in common:
the determination of a subset $S \subseteq V_0$.
A subset $S \subseteq V_0$ can be determined via an appropriate \textit{labeling algorithm},
which determines a partitioning of the network by assigning labels (integer) to each vertex.

The GSECs are the only constraints in our model which must be obligatorily
included through an exact separation procedure.
At a minimum, their inclusion must be devised
for integral solutions of the IP model of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}.
GSEC's can be separated exactly
by tracing the \textit{major connected components}
induced from the integral solution of the model.
Tracing the connected components can be used to determine subsets
$T \subseteq V | \sum_{e \in \delta(T)} x_e = 0$,
which constitutes a valid labeling of the network.
For fractional solutions, however, their exact separation is more complicated.
Let $x^\star \in \R^{|E|}$ denote the value of a fractional solution of
the linear relaxation in
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3},
then,
the GSECs can be separated (exactly) by solving $(u, v)$-min-cuts
on a flow network where capacities are given from the fractional solutions' value $x^\star$.
The $(u, v)$-min-cuts outputs a subset $T \subseteq V$ induced from $(u, v)$
minimizing the term $\sum_{e \in \delta(T)} x^\star_e$,
which constitutes a valid labeling of the network for each $u, v \in V,\ u \ne v$.

Instead, the exact separation of the RCC and GLM inequalities
is a different concern, refer to the respective discussion in \cref{sec:cptp-rcc,sec:cptp-glm}.
For the RCC inequalities,
no exact separation procedure is currently known \parencite{jepsen2014}.
For the GLM inequalities,
a cutting-plane strategy based on solving
$(u, v=0)$-min-cuts on a flow network with $u$-dependent capacities,
may be employed \parencite{letchford2006, jepsen2014}.

\medskip

In our implementation, with regard to the RCC and GLM inequalities,
we opted for a different approach compared to the one proposed in \textcite{jepsen2014}.
We re-use the same integral and fractional labeling algorithms
already employed for the optimal separation of the GSECs inequalities.
These two labeling algorithms will be shared between all the three families of inequalities.
This allows us to limit the programming efforts required to create custom
separation procedure
and also to tremendously reduce the computational impact,
since the same labeling procedures feed the separation of three different families of inequalities.
The labeling algorithms, and the separation procedures of each cuttin-plane,
is implemented in user-provided callbacks using the \textit{CPLEX generic callback API}.

\medskip

In the next two sections, \cref{sec:impl-labeling-integral-solutions,sec:impl-labeling-fractional-solutions},
we will describe the labeling algorithms employed for the integral solutions
and fractional solutions respectively.
Note however, that these two labeling algorithms
are only optimal for the separation of the GSECs inequalities,
while they behave suboptimally (heuristically) for the separation of the RCC and GLM inequalities.
In the remaining sections, instead,
we will discuss the separation of each implemented inequality.

\subsection{Labeling from Integral Solutions}
\label{sec:impl-labeling-integral-solutions}

Our integral labeling algorithm
is devised to be optimal for detecting violated integral GSECs inequalities
of \cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5},
but the same procedure is shared
to feed a suboptimal integral separation also for the GLM and RCC inequalities,
as shown in the block diagram in \cref{fig:integral-separation-block-diagram}.

Let $x^\star \in \Set*{0, 1}^{|E|},\ y \in \Set*{0, 1}^{|V|}$ denote the
current integral solution of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}.
If $x^\star, y^\star$ violates a GSEC constraint,
it is easy to verify that the solution models at least a spurious unconnected sub-tour that should be removed.
Unconnected sub-tours can be detected
by computing the \textit{major connected components}
through a Depth-First Search (DFS) traversal
on the network induced from the traversed edges:  $\Set*{e \in E \mid x^\star_e = 1}$.

\medskip

More formally,
let $C = \Set*{-1, 0, \dots, n_c - 1}$ denote the set of connected components
induced from the integral solution $x^\star \in \Set*{0, 1}^{|E|},\ y \in \Set*{0, 1}^{|V|}$.
A vertex $i \in V$ is said to belong to a singleton connected components,
if the connected component contains only $i$ itself, namely $y^\star_i = 0$.
We are only interested in modeling \textbf{major} connected components,
i.e. components containing at least two vertices.
We ignore singleton connected components,
and we associate the sentinel value $-1$ to encode all the vertices $i \in V$ belonging to singletons.
Therefore, the number $n_c \in \Z$ actually represents the number
of major connected components, which satisfies $n_c \ge 1$.
Equivalently,
$n_c$ represents the number of sub-tours formed in the current integral solution.
Let $cc(i) \in C$ be an array
which for each vertex $i \in V$ it encodes to which connected component it belongs to.
Note that the depot node always belongs to a connected component,
therefore by definition we fix $cc(0) = 0$.
For singletons instead we fix $cc(i) = -1  \quad \forall i \in V_0 \mid y^\star_i = 0$.
The connected components can be computed
by a simple DFS traversal, which pseudocode is provided in \cref{algo:cc-dfs}.

Consider the sets $T_k = \Set*{i \in V \mid cc(i) = k}$ with $k = 0, \dots, n_c$
computed from the just devised labeling algorithm.
Due to the construction of such sets,
by letting $k = 0, \dots, n_c$,
it holds that:
$|T_k| \ge 2$,
$\sum_{e \in \delta(T_k)} x^\star_e = 0$
and $\exists i \in T_k \mid y^\star_i = 1$,
thus ensuring the correctness of the whole branch-and-cut procedure.

\begin{algorithm}
	\caption{An algorithm for computing the major connected components through a Depth-First Search (DFS) traversal}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\KwResult{$n_c$: number of subtours formed}
	\KwResult{$cc[i] \in C$: connected component of $\forall i \in V$}
	\input{Content/Chapters/Snippets/cc-dfs-pseudoalgo.tex}
	\label{algo:cc-dfs}
\end{algorithm}

\begin{figure}[ht]
	\centering
	\framebox{\includegraphics[width=6cm]{Imgs/integral-separation-block-diagram.cropped.pdf}}
	\caption{A block diagram representing the structure
		of the employed separation structure for integral solutions
		along with the shared labeling algorithm.
	}
	\label{fig:integral-separation-block-diagram}
\end{figure}

\subsection{Labeling from Fractional Solutions}
\label{sec:impl-labeling-fractional-solutions}

Our fractional labeling algorithm is devised to be optimal for
detecting violated fractional GSECs inequalities
of \cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3},
but the same procedure is shared
to feed a suboptimal fractional separation also for the GLM and RCC inequalities,
as shown in the block diagram in \cref{fig:fractional-separation-block-diagram}.
This algorithm is inherently more difficult, and computationally expensive,
compared to the integral labeling algorithm.

A valid set $T \subseteq V$ can be separated for a fractional $x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$,
by solving a
max-flow problem between two arbitrary source and sink vertices $u, v \in V,\ u \ne v$ on a fully connected directed graph.
The max-flow problem is modeled through a directed symmetric flow network,
where the capacities $w_{ij} \in \R \quad \forall i, j \in V$
are given from the current fractional solution $w_{ij} = x^\star_{\Set*{i, j}} \quad \forall i, j \in V$.

A solution to the max-flow problem
outputs a maxflow $\maxflow(u, v)$ and a bipartition, also called "binary coloring",
of the set $V$,
namely two complementary sets $F_1(u, v),\ F_2(u, v)$
such that $F_1(u, v) \cup F_2(u, v) = V$, $F_1 \cap F_2 = \emptyset$ and $u \in F_1(u, v),\ t \in F_2(u, v)$.
The quantity $\deltaplus(F_1(u, v))$ constitutes the min-cut induced from solving the max-flow problem over $(u, v)$.
It is known that solving a maxflow problem guarantees the following two properties:
\begin{enumerate}
	\item Arcs $\{ (i, j) \mid i \in F_1(u, v),\ j \in F_2(u, v) \}$ are saturated
	\item Arcs $\{ (j, i) \mid i \in F_1(u, v),\ j \in F_2(u, v) \}$ are drained.
\end{enumerate}
Therefore the following result holds:
\begin{align}
	\sum_{(i, j) \in \deltaplus(F_1(u, v))} f_{ij}  & = \sum_{(i, j) \in \deltaplus(F_1(u, v))} x^\star_{\Set*{i, j}} & = \maxflow(u, v) \\
	\sum_{(i, j) \in \deltaminus(F_1(u, v))} f_{ij} & = \sum_{(i, j) \in \deltaplus(F_2(u, v))} f_{ij}                & = 0,
\end{align}
where $f_{ij}$ denotes the flow along the directed arcs $(i, j),\ i, j \in V$ in the corresponding flow network.

It is important to note that,
since we are dealing with a \textbf{symmetrical} flow network,
solving the maxflow problem between pairs $(u, v)$ and pair $(u, v)$ will output the same maxflow value,
i.e. $\maxflow(u, v) = \maxflow(v, u)$.
Although, and this is the more important aspect,
the induced bipartitions in the general case are not guaranteed to be symmetric.
Namely, in the general case we have that: $F_1(u, v) \ne F_2(v, u)$ and $F_2(u, v) \ne F_1(v, u)$.
To see this is the case, this simple flow network:
\begin{center}
	\begin{tikzpicture}[node distance={20mm}, main/.style = {draw, circle, fill=black!10!white}]
		\centering

		\node[main] (0) {$0$};
		\node[main] (1) [right of = 0] {$1$};
		\node[main] (2) [right of = 1] {$2$};
		\node[main] (3) [right of = 2] {$3$};
		\node[main] (4) [right of = 3] {$4$};

		\draw (0) -- (1) node [midway, yshift=2mm] {$0$};
		\draw (1) --  (2) node [midway, yshift=2mm] {$10$};
		\draw (2) --  (3) node [midway, yshift=2mm] {$10$};
		\draw (3) --  (4) node [midway, yshift=2mm] {$0$};
	\end{tikzpicture}
\end{center}
produces the same maxflow value when solving for $(0, 4)$ and $(4, 0)$ pair respectively,
and produces $F_1(0, 4) = \{ 0\},\ F_2(0, 4) = \{ 1, 2, 3, 4\}$, $F_1(4, 0) = \{ 4 \},\ F_2(4, 0) = \{ 0, 1, 2, 3\}$,
which clearly represent a non symmetric coloring.
This behavior is a direct consequence that flow networks don't guarantee unique min-cuts.

\medskip

In this thesis,
we used the push relabel max flow algorithm first developed in \cite{goldberg1997},
which in practice it is usually faster than more classical approaches such as the Ford-Fulkerson max-flow algorithm.
The push relabel max flow algorithm runs in $O(N^4)$ time,
and when combined with an exhaustive enumeration over all possible choices of $u, v \in V,\ u \ne v$,
can take up to $O(N^6)$ time.

The Gomory-Hu tree, first presented in \cite{gomory1961},
provides a way to compute the all pairs $(u, v)$ max-flows using only $N$ main max-flow computations.
A Gomory-Hu tree can be seen as a data structure that represents a simpler reduced flow network,
where max-flow computations become trivially solvable
through a single iteration of the Ford-Fulkerson algorithm in $\Theta(N^2)$.
Combining the Gomory-Hu tree and the push relabel max flow algorithm,
an exhaustive enumeration of all possible $(u, v)$ vertices takes up to $O(N^5)$ time to build the tree
and further $\Theta(N^4)$ to query for all the possible $F_1(u, v), F_2(u, v)$ bipartitions.

In our implementation
we exploited the Gomory-Hu tree to provide full enumeration of all possible $(u, v)$ maxflows.
For brevity reasons we will not list the pseudocode of the max-flow and Gomory-Hu tree algorithms.
Refer to the \urlref{https://github.com/dparo/master-thesis}{Github repository} for their respective implementation.

\medskip

We conclude the section by providing an implementation tip.
Writing fast and correct max-flow algorithms that operate directly with floating point arithmetic
can be difficult and error-prone due to accumulation of accuracies errors.
Any trivial implementation may "get stuck" in massively long loops pushing atomically small quantity of flows.
Careful attention must be paid when developing one such algorithm.
Good software engineering practices, such as unit testing, can help in spotting problematic implementations.

A simpler approach consists in implementing a maxflow algorithm that operates with integer arithmetic.
By exploiting that $x^\star$ is bounded in the $[0, 1]$ range,
we can multiply the fractional solution value $x^\star$ by a big-constant $M \in \R$ (e.g. $M = 10^6$)
and truncate its value when defining the capacities of the flow network.
The value $\maxflow(u, v)$ then needs to be remapped on the original scale
by dividing it by $M$.
For simplicity and stability, in our maxflow implementation we opted for the latter approach.

\begin{figure}[ht]
	\centering
	\framebox{\includegraphics[width=8cm]{Imgs/fractional-separation-block-diagram.cropped.pdf}}
	\caption{A block diagram representing the structure
		of the employed separation structure for fractional solutions
		along with the shared labeling algorithm.
	}
	\label{fig:fractional-separation-block-diagram}
\end{figure}

\subsection{GSEC Separation}
\label{sec:impl-gsec-separation}

\subsubsection{GSEC Integral Separation}
\label{sec:impl-gsec-integral-separation}

The GSEC integral separation procedure is the most important
separation procedure in our implementation,
since it is mandatory to ensure the correctness of the branch-and-cut algorithm.
GSECs inequalities which are violated by integral solutions
must be separated exactly and reported as is
(without employing violation thresholds) to the MIP optimizer.

The GSEC inequalities require for the identification of a subset $S \subseteq V_0,\ |S| \ge 2$.
Let $T_k  = \Set*{i \in V \mid cc(i) = k},\ |T_k| \ge 2 \quad \forall k \in \Set*{1, \dots, n_c}$ be the labeling
outputted from the major connected components as discussed in \cref{sec:impl-labeling-integral-solutions}.
By construction $n_c \ge 1,\ 0 \in T_0$.
Then a valid subset $S \subseteq V_0$ can be picked as $S = T_k \quad \forall k \in \Set*{1, \dots, n_c}$.
Which implies that,
any major connected component (i.e. sub-tour) that does not contain the depot node,
can be used as a valid set $S \subseteq V_0$ for separating GSEC inequalities from integral solutions.
If $n_c = 1$ then no $S \subseteq V_0$ can be separated,
which implies that the current integral solution models an optimal solution for the whole CPTP formulation
\labelcref{eq:cptp-obj-function,eq:cptp-depot-part-of-tour-constraint,eq:cptp-resource-upper-bound-constraint,eq:cptp-flow-conservation-constraint,eq:cptp-gsec-constraints,eq:cptp-x-mip-var-bounds,eq:cptp-y-mip-var-bounds}.

Let $x^\star \in \Set*{0, 1}^{|E|},\ y \in \Set*{0, 1}^{|V|}$ denote the
current integral solution of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}.
Recall the GSEC inequality definition in \cref{eq:cptp-gsec-constraints},
it is easy to verify that
$\sum_{e \in \delta(S)} x^\star_{e} = 0$, $y_i =  1 \quad \forall i \in S$
which implies that \cref{eq:cptp-gsec-constraints} cannot be satisfied by any $i \in S$.

\medskip

In a single integral separation iteration we can therefore separate:
\begin{equation}
	\sum^{n_c}_{k = 1} \SetSize*{ \Set*{ i \mid cc(i) = k \quad \forall i \in V } }
\end{equation}
violated GSECs inequality, which can be promptly reported to the MIP solver to reject the candidate integral solution.

A complete pseudocode of the GSEC integral separation procedure is provided in \cref{algo:gsec-integral-sep}.

\begin{algorithm}
	\caption{An algorithm for separating GSEC integral inequalities for the CPTP}
	\label{algo:gsec-integral-sep}
	\KwResult{$n_c$: number of major connected components}
	\KwData{$cc[i] \in C$: connected component $\forall i \in V$, see \cref{sec:impl-labeling-integral-solutions}}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\input{Content/Chapters/Snippets/gsec-integral-sep-pseudoalgo.tex}
\end{algorithm}

\subsubsection{GSEC Fractional Separation}
\label{sec:impl-gsec-fractional-separation}

The separation of GSEC inequalities for fractional solutions,
while it is non-strictly required for our implementation,
can dramatically reduce the number of branch nodes.

Let $\maxflow(u, v),\ F_1(u, v),\ F_2(u, v)$ denote the maxflow value and bipartitions
produced from the labeling algorithm described in \cref{sec:impl-labeling-fractional-solutions}.
A valid $S \subseteq V_0, |S| \ge 2$ for separating GSEC inequalities from fractional solution can be picked such that:
\begin{equation}
	S \subseteq V_0 =
	\begin{cases}
		F_1(u, v), & \texttt{if } 0 \notin F_1(u, v) \\
		F_2(u, v), & \texttt{otherwise}
	\end{cases},
	\qquad
	|S| \ge 2.
\end{equation}
Such approach can feed up to
$N^2 - N$ different sets $S \subseteq V_0$,
one for each possible pair $\Tuple*{u, v} \in V^2,\ u \ne v$

Let $x^\star \in \R^{|E|},\ y \in \R^{|V|}$ denote the
current fractional solution of
\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}.
Recall the GSEC inequality definition in \cref{eq:cptp-gsec-constraints},
it is easy to verify that $\sum_{e \in \delta(S)} x^\star_{ij} = \maxflow(u, v)$
holds due to the symmetry property of the flow network.

Therefore, any $i \in S$ that violates $\maxflow(u, v) \ge 2 y_i$
can be used to separate a violated GSEC inequality.
With such approach t is possible to separate $O(N^3)$ GSECs per fractional solution.
We noticed, through a quick empirical evaluation, that
generating and reporting all the encountered violated GSECs inequalities
led to a slow-down of the MIP optimizer.

\medskip
In our implementation we opted for a different approach by relaxing the conditions at which these cuts are reported.
For each subset $S \subseteq V_0,\ |S| \ge 2$, we report only the single most violated GSEC
associated to the customer $i \in V_0$ that maximizes the $\maxflow(u, v) - 2 y_i$ violation.
On top of that, to limit the number of weak GSEC inequalities that are reported to the MIP optimizer,
we define a violation threshold $\varepsilon_{\mt{GSEC}}$ and report the associated cut only if:
\begin{equation}
	\maxflow(u, v) \ge 2 y_i - \varepsilon_{\mt{GSEC}}
\end{equation}
is violated.
In our implementation we picked $\varepsilon_{\mt{GSEC}} = \epsGsecFValue$.

A complete pseudocode of the GSEC fractional separation procedure is provided in \cref{algo:gsec-frac-sep}.

\begin{algorithm}
	\caption{An algorithm for separating GSEC fractional inequalities for the CPTP}
	\label{algo:gsec-frac-sep}
	\KwData{$\maxflow(u, v), F_1(u, v), F_2(u, v)$: maxflow and bipartitions induced from $(u, t)$-min-cut, see \cref{sec:impl-labeling-fractional-solutions}}
	\KwData{$x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$: current fractional solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}
	}
	\input{Content/Chapters/Snippets/gsec-frac-sep-pseudoalgo.tex}
\end{algorithm}

\subsection{RCC separation}
\label{sec:impl-rcc-separation}

The RCC inequalities, defined in \cref{eq:cptp-rcc-inequality},
require for the identification of a subset $S \subseteq V_0, |S| \ge 1$.
Such inequalities can be rewritten in the following form:
\begin{equation}
	\ExprCptpFlowExiting{S} - \ExprCptpServedDemandWithWeight{S}{i}{\frac{2 q_i}{\ExprQr(S)}}    \ge   2 \left( \ceil*{ \frac{q(S)}{Q}} - \frac{q(S)}{Q_{\mathrm{R}}(S)} \right) \quad \forall S \subseteq V_0,\ |S| \ge 1.
\end{equation}

We first describe the separation of the RCC inequalities for integral solutions.
Such separation procedure follows roughly the same reasoning
employed for the GSEC integral separation discussed in \cref{sec:impl-gsec-integral-separation}.
Namely, let $T_k  = \Set*{i \in V \mid cc(i) = k},\ |T_k| \ge 2 \quad \forall k \in \Set*{1, \dots, n_c}$ be the labeling
outputted from the major connected components as discussed in \cref{sec:impl-labeling-integral-solutions}.
Then a valid subset $S \subseteq V_0,\ |S| \ge 1$ can be picked as $S = T_k \quad \forall k \in \Set*{1, \dots, n_c}$.
After picking the appropriate subset $S$ we test for the violation of the inequality.
Only if the associated RCC inequality is violated it is reported to the MIP optimizer.
A complete pseudocode is provided in \cref{algo:rcc-integral-sep}.

Next we describe the separation of the RCC inequalities for fractional solutions.
Such separation procedure also follows roughly the same reasoning
for the GSEC fractional separation discussed in \cref{sec:impl-gsec-fractional-separation}.
Let $\maxflow(u, v),\ F_1(u, v),\ F_2(u, v)$ denote the maxflow value and bipartitions
produced from the labeling algorithm described in \cref{sec:impl-labeling-fractional-solutions}.
A valid $S \subseteq V_0, |S| \ge 2$ for separating RCC inequalities
from fractional solution can be picked such that:
\begin{equation}
	S \subseteq V_0 =
	\begin{cases}
		F_1(u, v), & \texttt{if } 0 \notin F_1(u, v) \\
		F_2(u, v), & \texttt{otherwise}
	\end{cases}.
\end{equation}
After picking the appropriate subset $S$ we test for violation of the inequality,
but as is the case for fractional separation,
we employ a non-zero violation threshold $\varepsilon_{\mt{RCC}}$.
In our implementation we set $\varepsilon_{\mt{RCC}} = \epsRccFValue$.
With such an approach we can separate $O(N^2)$ RCCs per fractional solution.
A complete pseudocode is provided in \cref{algo:rcc-frac-sep}.

\begin{algorithm}
	\caption{An algorithm for separating RCC integral inequalities for the CPTP}
	\label{algo:rcc-integral-sep}
	\KwResult{$n_c$: number of major connected components}
	\KwData{$cc[i] \in C$: connected component $\forall i \in V$, see \cref{sec:impl-labeling-integral-solutions}}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\input{Content/Chapters/Snippets/rcc-integral-sep-pseudoalgo.tex}
\end{algorithm}

\begin{algorithm}
	\caption{An algorithm for separating RCC fractional inequalities for the CPTP}
	\label{algo:rcc-frac-sep}
	\KwData{$\maxflow(u, v), F_1(u, v), F_2(u, v)$: maxflow and bipartitions induced from $(u, t)$-min-cut, see \cref{sec:impl-labeling-fractional-solutions}}
	\KwData{$x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$: current fractional solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}
	}
	\input{Content/Chapters/Snippets/rcc-frac-sep-pseudoalgo.tex}
\end{algorithm}

\subsection{GLM separation}
\label{sec:impl-glm-separation}

The GLM inequalities, defined in \cref{eq:cptp-glm-inequality},
require for the identification of a subset $S \subseteq V_0, |S| \ge 2$.
Such inequalities can be rewritten in the following form:
\begin{equation}
	\sum\limits_{
		\EqStackTwo{e = \Set*{i,j} \in \delta(S)}{i \in S,\ j \notin S}
	} x_e \Expr*{1 - 2 \frac{q_j}{Q}}
	- \sum\limits_{i \in S} \frac{2 q_i}{Q} y_i
	\ge 0 \quad \forall S \subseteq V_0,\ |S| \ge 2
	.
\end{equation}

We first describe the separation of the GLM inequalities for integral solutions.
Such separation procedure follows roughly the same reasoning
employed for the GSEC integral separation discussed in \cref{sec:impl-gsec-integral-separation}.
Namely, let $T_k  = \Set*{i \in V \mid cc(i) = k},\ |T_k| \ge 2 \quad \forall k \in \Set*{1, \dots, n_c}$ be the labeling
outputted from the major connected components as discussed in \cref{sec:impl-labeling-integral-solutions}.
Then a valid subset $S \subseteq V_0,\ |S| \ge 2$ can be picked as $S = T_k \quad \forall k \in \Set*{1, \dots, n_c}$.
After picking the appropriate subset $S$ we test for the violation of the inequality.
Only if the associated GLM inequality is violated it is reported to the MIP optimizer.
A complete pseudocode is provided in \cref{algo:glm-integral-sep}.

Next we describe the separation of the GLM inequalities for fractional solutions.
Such separation procedure also follows roughly the same reasoning
for the GSEC fractional separation discussed in \cref{sec:impl-gsec-fractional-separation}.
Let $\maxflow(u, v),\ F_1(u, v),\ F_2(u, v)$ denote the maxflow value and bipartitions
produced from the labeling algorithm described in \cref{sec:impl-labeling-fractional-solutions}.
A valid $S \subseteq V_0, |S| \ge 2$ for separating GLM inequalities
from fractional solution can be picked such that:
\begin{equation}
	S \subseteq V_0 =
	\begin{cases}
		F_1(u, v), & \texttt{if } 0 \notin F_1(u, v) \\
		F_2(u, v), & \texttt{otherwise}
	\end{cases},
	\qquad
	|S| \ge 2.
\end{equation}
After picking the appropriate subset $S$ we test for violation of the inequality,
but as is the case for fractional separation,
we employ a non-zero violation threshold $\varepsilon_{\mt{GLM}}$.
In our implementation we set $\varepsilon_{\mt{GLM}} = \epsGlmFValue$.
With such an approach we can separate $O(N^2)$ GLMs per fractional solution.
A complete pseudocode is provided in \cref{algo:glm-frac-sep}.

\begin{algorithm}
	\caption{An algorithm for separating GLM integral inequalities for the CPTP}
	\label{algo:glm-integral-sep}
	\KwResult{$n_c$: number of major connected components}
	\KwData{$cc[i] \in C$: connected component $\forall i \in V$, see \cref{sec:impl-labeling-integral-solutions}}
	\KwData{$x^\star \in \Set*{0, 1}^{|E|},\ y^\star \in \Set*{0, 1}^{|V|}$: current integral solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3,eq:cptp-static-model-4,eq:cptp-static-model-5}
	}
	\input{Content/Chapters/Snippets/glm-integral-sep-pseudoalgo.tex}
\end{algorithm}

\begin{algorithm}
	\caption{An algorithm for separating GLM fractional inequalities for the CPTP}
	\label{algo:glm-frac-sep}
	\KwData{$\maxflow(u, v), F_1(u, v), F_2(u, v)$: maxflow and bipartitions induced from an arbitrary $s \ne t, s \in V, t \in V$ pair}
	\KwData{$x^\star \in \R^{|E|},\ y^\star \in \R^{|V|}$: current fractional solution of
		\cref{eq:cptp-static-model-0,eq:cptp-static-model-1,eq:cptp-static-model-2,eq:cptp-static-model-3}
	}
	\input{Content/Chapters/Snippets/glm-frac-sep-pseudoalgo.tex}
\end{algorithm}
