\chapter{Branch and Price}
\label{sec:branch-and-price}

In this chapter,
we will discuss the branch-and-price (BAP) framework and the \textit{Column Generation} (CG) approach,
which are two fundamental components used by modern CVRP solvers.
The focus of our presentation will be on these two critical components in the context of the CVRP.
For a review of CG approaches to solving arbitrary MIP problems, see \textcite{vanderbeck2005, lubbecke2005, desrosiers2011}.
Moreover, see \textcite{barnhart1998, desrosiers2005}
for a primer introduction to branch-and-price schemes.
We refer the reader to \textcite{feillet2010}'s work,
which includes a helpful tutorial on CG and BAP algorithms specific to VRPs.

Branch-and-price (BAP) frameworks are in essence a branch-and-bound (BAB) scheme \parencite{land2010}
that originates when solving the SP/SC formulation for VRPs (see \cref{sec:set-partitioning-formulation}).
To seek the optimal solution,
BAB-based schemes use a search tree and a pruning strategy by bounding the objective function.
As opposed to widerspread branch-and-cut (BAC) frameworks,
their primary focus is the usage of a Column Generation (CG) technique for improving the dual bound,
see \textcite{righini2008}.
BAP frameworks were first applied successfully to the Cutting Stock problem in \textcite{gilmore1961}.
The so-called branch-price-and-cut (BPC) extends the traditional BAP framework.
Additional cutting planes are added in the BPC framework to strengthen the linear relaxations
associated with each node, further improving the dual bounds.

In the following section \labelcref{sec:column-generation-and-pricing-problem}
we will illustrate the column generation algorithm
and the pricing problem, two vital pieces in branch-and-price frameworks.

\section{Column generation and the Pricing Problem}
\label{sec:column-generation-and-pricing-problem}

Consider the \textit{Master Problem} (MP) defined
as the linear relaxation of the SP formulation
\labelcref{eq:set-partitioning-obj-func,eq:set-partitioning-K-routes,eq:set-partitioning-customers-visited-by-exactly-one-route,eq:set-partitioning-lambda-mip-var-bounds}
obtained by relaxing the integrality constraints:
\begin{align}
	\min_{\lambda} \quad z_\mt{MP}(\lambda) & = \sum_{p \in P}  c_p \lambda_p      & \label{eq:mp-obj-func}                                                                                                    \\
	                                        & \sum_{p \in P} \lambda_{p} = K       & \label{eq:mp-K-routes}                                                                                                    \\
	                                        & \sum_{p \in P}  a_{ip} \lambda_p = 1 & \quad \forall i \in V_0                                              \label{eq:mp-customers-visited-by-exactly-one-route} \\
	                                        & 0 \le \lambda_p \le 1                & \quad \forall p \in P \label{eq:mp-lambda-mip-var-bounds}.
\end{align}
The constraint $\lambda_p \le 1$ in \labelcref{eq:mp-lambda-mip-var-bounds}
is implied from \labelcref{eq:mp-customers-visited-by-exactly-one-route} and can thus be removed.
An optimal solution to the MP provides a valid dual bound at the root node of the search tree.
The MP can be extended by adding additional cuts or branching constraints
with the aim of improving the dual bounds.

The dual problem associated with
\labelcref{eq:mp-obj-func,eq:mp-customers-visited-by-exactly-one-route,eq:mp-K-routes,eq:mp-lambda-mip-var-bounds}
is:
\begin{align}
	\max_{\pi} \quad z_\mt{DMP}(\pi) & =  K \pi_0 + \sum_{i \in V_0} \pi_i           & \label{eq:dmp-obj-func}                             \\
	                                 & \pi_0 + \sum_{i \in V_0} a_{ip} \pi_i \le c_p & \quad \forall p \in P \label{eq:dmp-constraint1}    \\
	                                 & \pi_0 \in \R                                  & \label{eq:dmp-constraint2}                          \\
	                                 & \pi_i \in \R                                  & \quad \forall i \in V_0 \label{eq:dmp-constraint3},
\end{align}
where $\pi_0 \in \R, \pi_i \in \R \quad \forall i \in V_0$ represents the dual variables
associated respectively with constraints \labelcref{eq:mp-K-routes,eq:mp-customers-visited-by-exactly-one-route}.
In case the SC formulation
\labelcref{eq:set-covering-obj-func,eq:set-covering-K-routes,eq:set-covering-customers-visited-by-exactly-one-route,eq:set-covering-lambda-mip-var-bounds}
is used to define the MP,
\cref{eq:dmp-constraint3} in
\labelcref{eq:dmp-obj-func,eq:dmp-constraint1,eq:dmp-constraint2,eq:dmp-constraint3}
can be replaced in favor of $\pi_i \ge 0 \quad \forall i \in V_0$,
thus slimming the dual space.

When solving the MP,
at each iteration of the \textit{simplex algorithm} \parencite{dantzig1955}
we seek a non-basic variable known as \textit{column},
to price out and enter the basis through evaluation of the dual variables $\pi \in \R^N$.
Due to the enormous size of the set of routes $P$,
evaluating the dual variables $\pi \in \R^{N}$ is computationally intractable.

\medskip

As a result, in BAP frameworks we consider only a small subset of columns $\mcP \subseteq P$,
yielding the following linear program:
\begin{align}
	\min_{\lambda} \quad z_\mt{RMP}(\lambda) & = \sum_{p \in \mcP}  c_p \lambda_p      & \label{eq:rmp-obj-func}                                                                                                    \\
	                                         & \sum_{p \in \mcP} \lambda_{p} = K       & \label{eq:rmp-K-routes}                                                                                                    \\
	                                         & \sum_{p \in \mcP}  a_{ip} \lambda_p = 1 & \quad \forall i \in V_0                                              \label{eq:rmp-customers-visited-by-exactly-one-route} \\
	                                         & \lambda_p \ge 0                         & \quad \forall p \in \mcP \label{eq:rmp-lambda-mip-var-bounds},
\end{align}
which takes the name of \textit{Restricted Master Problem} (RMP).

We look for a column to enter the basis,
which in turn necessitates the resolution of the following sub-problem:
\begin{equation}\label{eq:pp-problem}
	{c^\star_p} = \min_{p \in P} \Set*{ \bar{c}_p = \sum_{e = \Set*{i, j} \in E} \Expr*{c_{e} - \frac{\pi_i + \pi_j}{2}} a_{ep}  },
\end{equation}
which takes the famous name of \textit{Pricing Problem} (PP).
In \labelcref{eq:pp-problem}, $\bar{c}_p$ denotes the reduced cost of a route $p \in P$
and $c^\star_p$ is the reduced cost of the optimal route $p^\star \in P$
that leads to the best dual bound improvement.
Notice that $\bar{c}_p$ can also be expressed as $\bar{c}_p = c_p - \pi_0 - \sum_{i \in V_0} \pi_i a_{ip}$.
For convenience,
we define $\bar{c}_{e} = c_{e} - \frac{\pi_i + \pi_j}{2}$
as the reduced cost of an edge $e\in E$.
The purpose of the RMP is to provide dual variables
to be transferred to the pricing sub-problem \parencite{lubbecke2005}.

Any $p \in P$ which satisfies $\bar{c}_p < 0$ is a valid column which can enter the basis of the RMP.
The BAP solver must intelligently manage the set $\mcP \subseteq P$ that it stores within a pool.
During the resolution process, the BAP framework manages which routes to keep or drop from $\mcP$.
Because the set $\mcP$ is generally sparse,
any $p \in \mcP \mid \lambda_p = 0$ is a valid candidate to be dropped from the pool.
A BAP framework must be appropriately engineered to maintain
the size of the pool $\mcP \subseteq P$ manageable.

\medskip

In the literature, the resolution method, or algorithm,
used to solve the PP is known as \textit{oracle} or \textit{pricer}.
The oracle needs to solve the pricing sub-problem which, due to the definition of the set $P$,
coincides with solving an \textit{Elementary Shortest Path Problem with Resource Constraints} (ESPPRC)
over a \textbf{new directed symmetric} network with weights
$\bar{c}_{ij} = c_{ij} - \frac{1}{2} \pi_i - \frac{1}{2} \pi_j$.
Resources are monotonically increasing quantities,
such as capacity or time,
which restrict the feasibility of a route.
The ESPPRC asks for an elementary route
connecting a \textit{source vertex} and a \textit{sink vertex}
that satisfies the resource consumption bounds.
Because of the elementarity condition, the route can only visit each vertex at most once.
In the ESPPRC, the depot node is split into two vertices (one source, one sink)
and the newly obtained network is characterized by $N + 1$ vertices.
\Cref{sec:the-pricing-problem} will go over the PP and the ESPPRC in more details.

\medskip

The \textit{Column Generation} (CG) is an iterative algorithm,
successfully applied to a wide variety of problems \parencite{desrosiers2005},
which alternates between two phases \parencite{desaulniers2018}:
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}

	\item The simplex algorithm for solving the RMP, which is characterized by one or more pivot operations.
	\item One or several iterations of the Pricing Problem (PP) solved by invoking the pricer algorithm.
	      The simplex algorithm invokes the pricer to verify whether other pivot operations
	      can be performed for improving the dual bound.
	      The pricer algorithm usually lives in a separate external code module from the branch-and-price code.
\end{enumerate}

The column generation may also be interpreted
as a cutting-plane strategy for the dual problem.
The column generation procedure stops mainly under two scenarios:
(i) when no more negative reduced cost routes exist,
i.e. the PP outputs a $p^\star \in P$ achieving $c^\star_p \ge 0$
or
(ii) the CG procedure tails off,
i.e. the gained dual bound improvements
compared to the running time to generate a column
become suboptimal (optional).

If after the column generation procedure
the candidate solution to the RMP $\lambda^*$ satisfies the integrality constraints,
$\lambda^\star_p \in \Set*{0, 1} \quad \forall p \in \mcP$,
no branching or cutting planes are required
and the candidate solution $\lambda^*$ can update the incumbent.
If, instead,
$\exists p \in \mcP \mid \lambda^\star_p \notin \Set*{0, 1}$
then a branching strategy is usually necessary
to seek the best integral solution.
When all the nodes of the branch-and-bound tree have been explored or pruned,
then the CVRP problem is solved to optimality
and the incumbent solution becomes the optimal solution
$(p_1, \dots, p_K) \mid \lambda^\star_{p_i} = 1$.

\medskip

It's also worth noting that
the CG doesn't have to solve the PP optimally
every time the simplex algorithm advances.
Finding any $p \in P$ that achieves $\bar{c}_p < 0$ is usually enough to improve the dual bound.
Except for proving the optimality at the last CG iteration,
there is commonly no need to solve the pricing problem exactly.
Therefore, fast and efficient heuristic algorithms may be employed
to tackle the pricing problem,
especially during the very first few pricing iterations,
where finding reduced cost columns is effortless.

\section{Branching, Route Enumeration and Cut Generation}
\label{sec:branching-and-cut-generation-within-bap-frameworks}

Solving the RMP at the root node rarely suffices to satisfy
the integrality constraints for the SP formulation
\labelcref{eq:set-partitioning-obj-func,eq:set-partitioning-K-routes,eq:set-partitioning-customers-visited-by-exactly-one-route,eq:set-partitioning-lambda-mip-var-bounds}.
The CG algorithm may conclude with a non-zero duality gap.
As a result,
a search tree and a branching scheme are used to find
the best integral solution $\lambda^\star_p \in \Set*{0, 1} \quad \forall p \in P$.
Modern BAP frameworks employ additional cutting planes
to improve the dual bounds and the overall convergence speed.
The so-called branch-price-and-cut (BPC)
combines common elements from BAP and BAC frameworks.
\textcite{fukasawa2006, ropke2012} are two notable works that integrate
cutting planes and propose a BCP approach for the VRP.
See \textcite{sadykov2019modern} for a discussion of the cutting-edge components
that comprise modern BAP/BPC frameworks.

\medskip

However, it's important to note that branching isn't a rigidly required operation.
\textit{Route enumeration} (RE), first proposed for the CVRP in \textcite{baldacci2008},
is a technique complementary to branching.
In RE, all elementary routes that may be part of the VRP optimal solution are identified
and later incorporated into an exhaustive SP formulation.
The SP formulation is then solved using a standard MIP optimizer.
Enumeration is accomplished through a dynamic programming labeling algorithm similar
to the one employed for the PP (see the subsequent discussion in \cref{sec:solving-the-pricing-problem}).
The issue with RE is the potentially large number of routes that needs enumeration.
This number is directly proportional
to the tightness of the duality gap
and the average length of a tour $N / K$ \parencite{toth2014}.
Route enumeration is an operation that requires exponential space complexity,
but it can drastically improve the performance of the BPC in some circumstances.
\textcite{baldacci2008,baldacci2011} are two considerable BAP contributions
replacing branching entirely in favor of RE.

Modern BPC frameworks instead take a hybrid approach by combining branching and route enumeration (RE)
(see \cite{pessoa2008, pessoa2009,contardo2014,pecin2017improved,pecin2017new,pessoa2020}).
Route enumeration is attempted after the column generation has converged.
If the number of enumerated routes exceeds a predefined limit, the RE is preemptively aborted,
and traditional branching is applied instead.
Once the primal-dual bound gap  $\bar{z} - \ubar{z}$ eventually reaches reasonable levels,
the RE strategy will enumerate all routes under the maximum limit.
The associated RMP formulation can now be solved efficiently using a standard MIP optimizer.

We will not go into detail about route enumeration in this thesis
because its presence has no impact on the pricing problem.
Nonetheless, acknowledging its existence and role within a branch-and-price framework is essential.

\medskip

Due to the PP's existence,
branching and cut generation in BCP frameworks are more delicate operations
than in traditional BAC frameworks.
According to \textcite{dearagao2003},
there are two types of inequalities that can occur
depending on the branching and cut generation schemes utilized:
\textbf{robust} and \textbf{non-robust} inequalities.

A \textbf{robust} inequality is an inequality
which can be safely added to the RMP
without altering the structure of the set of feasible paths $P$ \parencite{fukasawa2006}.
That is,
robust inequalities do not require explicit modeling in the PP formulation
and instead manifest their contribution directly in the reduced cost edges $\bar{c}_e$.
An oracle, therefore,
after the introduction of a robust inequality in the RMP,
needs to solve the same ESPPRC problem
but with slightly different weights associated with each edge.

A \textbf{non-robust} inequality, on the other hand,
is significantly harder to cope with
because it influences the structure of the set of possible paths $P$.
In general,
non-robust inequalities have an enriched potential to lower the integrality gap,
but they require explicit modeling and oracle support.
These inequalities can significantly complicate the PP
by exchanging better dual-bound improvements for longer column generation times.
As a result, their inclusion should be evaluated on an individual basis \parencite{desaulniers2011}.
Non-robust inequalities can arise during both the branching and cut-generation phases.

These work's contributions will predominantly focus
on \textbf{robust inequalities} exclusively.

\subsection{Branching}
\label{sec:bap-branching}

In this section, we will introduce branching for the SP formulation,
under the assumption that a branch-and-price scheme is employed
for solving the CVRP.

At first glance,
it might seem reasonable to branch directly on the $\lambda_p$ variables of the SP formulation.
Unfortunately, such branching has two significant drawbacks \parencite{vanderbeck2010reformulation}.
For starters,
it is not robust and leads to a harder PP: an ESPPRC with forbidden paths \parencite{villeneuve2005}.
Second, it results in an utterly unbalanced search tree.

A vast bulk of CVRP branching approaches investigated in the literature are
merely extensions of TSP branching schemes.
\textit{Branching on edge},
first applied to the CVRP in \textcite{christofides1969},
is one of the most basic branching schemes, but it is also one of the most effective.
The branching on edges scheme was refined in diverse forms in \textcite{fisher1994, miller1995}.
The edge flow decision variables can be calculated from the MP by noting that:
\begin{equation}
	x_e = \sum_{p \in P} a_{ep} \lambda_p  \quad \forall e \in E,
\end{equation}
where $a_{ep}$ represents the number of times route $p \in P$ crosses an edge $e \in E$.

Given a candidate fractional solution $0 \le \lambda^\star_p \le 1 \quad \forall p \in \mcP$
and a valid edge $e \in E \mid x_e \notin \Set*{0, 1, 2}$ to branch on,
it is possible to generate two descendant nodes in the search tree
to continue scanning for integral solutions:
\begin{equation}\label{eq:sp-branching-on-edges}
	x_e \le \floor*{\sum_{p \in \mcP} a_{ep} \lambda^\star_p}, \quad
	x_e > \ceil*{\sum_{p \in \mcP} a_{ep} \lambda^\star_p}.
\end{equation}

Branching on edges is an approach that is both extremely simple and robust.
Let $\omega_e \in \R$ denote the dual variable associated with edge $e \in E$
and one of the branching polarities in \cref{eq:sp-branching-on-edges},
then the new reduced cost $\bar{c}_e$ for an edge $e \in E$ after branching is:
\begin{equation}
	\bar{c}_e = c_e - \frac{\pi_i + \pi_j}{2} - \omega_e,
\end{equation}
where $\pi \in \R^N$ represents the dual variables associated with
\cref{eq:mp-K-routes,eq:mp-customers-visited-by-exactly-one-route}.

Branching on edges has the disadvantage of achieving only local changes
to the fractional solution.
For this reason, \textcite{augerat1998} propose an
approach to obtain larger perturbations.
They achieve this by branching on Rounded Capacity Constraints (RCCs) defined over
an arbitrary set $S \subseteq V_0$ with two descendant nodes:
\begin{equation}\label{eq:sp-branching-on-cutsets}
	\sum_{e \in \delta(S)}x_e \le 2 r(S), \quad
	\sum_{e \in \delta(S)}x_e \ge 2 r(S) + 2
\end{equation}
\textcite{pecin2017improved} apply a similar branching approach.

\textit{Ryan and Foster branching} \parencite{ryan1981integer}
is another viable branching rule which is unfortunately non-robust.
\textit{Ryan and Foster branching} complicates the pricing subproblem,
but it has the primary benefit of resulting in more balanced search trees.
\textit{Branching over the accumulated resource consumption}, proposed in \textcite{gelinas1995new},
is another viable branching rule that,
unlike the previous one, it does not raise the pricing difficulty.

\textit{Strong branching} is a commonly employed strategy,
which evaluates individually potential branching candidates
by measuring their impact based on some scoring function.
The goal is to choose either the branching candidate
that heuristically leads to the best dual bound improvement
or the branching candidate that heuristically leads to a more balanced search tree.
Strong branching can reduce the size of the search tree
at the expense of a slower branching candidate evaluation.
\textcite{fukasawa2006, pecin2017limited, pecin2017new} are all approaches
that opted for the strong branching technique for solving the VRP.

\medskip

Reduction rules can remove edges verified to not belong to an optimal solution.
\textit{Variable fixing} can be used as a reduction rule
by utilizing a dual bound $\bar{z}$ and primal bound $\ubar{z}$
to eliminate some edges $e \in E \mid \hat{c}_e \ge \bar{z} - \ubar{z}$ \parencite{hadjar2006, irnich2010}.
Reduction rules are a peculiar form of branching where only single descendant nodes are generated.
Reduction rules may crop a good portion of the search space.

\subsection{Cutting Planes}
\label{sec:bap-cutting-planes}

In this section, we will introduce numerous families of inequalities
which can be used for cut generation
for the 2F
\labelcref{eq:two-index-flow-obj-func,eq:two-index-flow-two-edges-incident-per-customer,eq:two-index-flow-two-k-edges-incident-in-the-depot-node,eq:two-index-flow-ccc,eq:two-index-flow-x-mip-var-bounds-depot,eq:two-index-flow-x-mip-var-bounds}
and the SP
\labelcref{eq:set-partitioning-obj-func,eq:set-partitioning-K-routes,eq:set-partitioning-customers-visited-by-exactly-one-route,eq:set-partitioning-lambda-mip-var-bounds}
formulations.
See \textcite{desaulniers2011} for a general framework
on cutting planes for CG algorithms for arbitrary integer programs.

While the 2F formulation is not the primary focus of this thesis,
presenting and studying valid inequalities for such a formulation
will be useful for the PP induced during the CG phase.
Many 2F valid inequalities can be applied to the ESPPRC if properly rewritten.
The early attempts to propose valid inequalities to improve the linear relaxation
for the 2F problem were obtained by generalizing the constraints
for the traditional TSP problem, see \textcite{naddef1993}.
\citeauthor{naddef1993} demonstrated that by putting any valid inequality obtained for the TSP
into a proper tight triangular form, it is possible to re-adapt it to the CVRP.
As an example, the comb inequalities readjusted from the original TSP
\parencite{chvatal1973,grotschel1979,augerat1995approche}.

Valid inequalities for the 2F CVRP formulation can be classified into several groups \parencite{toth2014}.
We concentrate on the following groups: capacity constraints and multistar inequalities.

The \textbf{capacity constraints} are inequalities which can be expressed in the form
$\sum_{e \in \delta(S)} x_e \ge 2 r(S) \quad \forall S \subseteq V_0, |S| \ge 2$.
This set of constraints may have different names depending on how $r(S)$ is defined.
If $r(S) = \sum_{i \in S} q_i / Q$, we obtain the so-called Fractional Capacity Constraints (FCC).
Instead, if we use the typical Bin Packing Problem (BPP) lower bound, $r(S) = \ceil*{\sum_{i \in S} q_i / Q}$, we obtain the so-called Rounded Capacity Constraints (RCC).
The RCC were first presented in \textcite{laporte1983} for the CVRP 2F formulation.

The \textbf{multistar inequalities} were initially proposed in \textcite{araque1990}
for the \textit{CVRP with unit demands},
then extended to the generic CVRP in \textcite{gouveia1995, achuthan1998},
and finally generalized in the so called Generalized Large Multistart (GLM)
for the CVRP in \textcite{letchford2002,letchford2006}.
Given two disjoint sets of customers $A, B \subseteq V_0 \mid A \cap B = \emptyset$,
and $\alpha, \beta, \gamma \in \R$,
a multistar inequality is described in the 2F formulation using the following template:
\begin{equation}
	\alpha \sum_{e \in E(A)} x_e + \beta \sum_{e \in \Expr*{\delta(A) \cap \delta(B)}} x_e \le \gamma.
\end{equation}
\textcite{araqueg1994} were the first to successfully apply multistar inequalities
within a branch-and-cut framework.
\textcite{letchford2006} demonstrates that GLMs are implied by the SP model,
even if the set of feasible paths $P$ is relaxed to contain non-elementary routes.

\medskip

We will terminate the remainder of this section
by introducing some families of inequalities
serviceable to improve the linear relaxation for the SP formulation
\labelcref{eq:set-partitioning-obj-func,eq:set-partitioning-K-routes,eq:set-partitioning-customers-visited-by-exactly-one-route,eq:set-partitioning-lambda-mip-var-bounds}.
Despite the SP formulation generally delivers better dual bounds
compared to other CVRP formulations (see discussion in \cref{sec:set-partitioning-formulation}),
these bounds may still be too weak to obtain an efficient algorithm.
Thus, it is common practice to introduce cutting-plane approaches
in modern BAP-based VRP solvers.

Cutting planes that only involve edge-flow variables are by nature robust.
Because the RCC inequalities only involve the edges
$e \in E$ crossing a set $S \subseteq V_0,\ |S| \ge 2$,
they trivially can be extended to a robust inequality for the SP formulation:
\begin{equation}
	\sum_{p \in P} \sum_{e \in \delta(S)}  a_{ep} \lambda_p \ge r(S),
\end{equation}
where $\sum_{e \in \delta(S)} a_{ep}$ counts the number of times a route $p \in P$
enters or leaves a set $S$
and $r(S)$ represents the number of trucks needed to serve each customer $i \in S$.
\textcite{lysgaard2003cvrpsep} proposes a heuristic algorithm
for efficiently separating the RCC inequalities.

\medskip

Robust cuts are moderately effective at closing the integrality gap,
but they may not be sufficient for some complicated VRP instances.
Consequently, some researchers attempted to apply non-robust cuts to the CVRP with promising success.
Non-robust cuts must be separated carefully to use them effectively.
Taking into account the aggravation of the pricing problem during the separation
of non-robust cuts is of vital importance for the overall performance of the BAP scheme.
While we will mostly avoid non-robust cuts in this thesis,
it is noteworthy to acknowledge their significance within a BAP framework.

Traditionally, these types of cutting planes have been handled by extending the
dynamic programming labeling algorithm
through the addition of fictitious resources and modifications to the dominance rules.
See discussion in \cref{sec:solving-the-pricing-problem} for more details.

\medskip

Major contributions in the non-robust cutting planes domain for the VRP are:
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}

	\item \textbf{Strengthened Capacity Cuts (SCCs)}, sometimes also called \textit{Strong Capacity Cuts}
	      were first proposed in \textcite{baldacci2008},.
	      These cutting planes can be considered a non-robust tighter version of the RCCs.
	      Compared to RCCs, they are not affected by routes entering set $S \subseteq V_0$ more than once.
	\item \textbf{Extended Capacity Cuts (ECCs)} proposed in \textcite{pessoa2008, pessoa2009}
	      are another pertinent generalization of the RCCs.
	\item \textbf{Subset Row Cuts (SRCs)} proposed in \textcite{jepsen2008subsetrow},
	      are non-robust inequalities obtained as a subset of the
	      Chv\'atal-Gomory rank-1 cuts \parencite{chvatal1973}
	      applied to a subset $C \subseteq V_0$ of customers.
	      Their separation is NP-hard.
	      Therefore, the subset $C$ is typically separated through enumeration
	      and for computational tractability the evaluation is restricted solely to $\forall C \subseteq V_0$
	      that satisfy $|C| \le 5$.
	      3-SRCs, namely SRCs where $|C| = 3$, were applied successfully in many works \parencite{desaulniers2008, jepsen2011, baldacci2011, contardo2014, pecin2017improved}.
	      The SRCs were later generalized to a more general Chv\'atal-Gomory Rank-1 cuts (R1Cs) in \textcite{petersen2008}.
	      R1Cs have the potential to be extremely powerful, but they make pricing subproblems significantly more difficult.
	      \textcite{baldacci2011} propose a weakened variant of the 3-SRCs inequalities.
	\item \textbf{Limited Memory Subset Row Cuts (lm-SRCs)} proposed in \textcite{pecin2017improved},
	      are a dynamically controlled weakening of the SRCs that has far less computational impact on the PP.
	      Later, \textcite{pecin2017limited} extend this reasoning
	      and develop the so-called Limited Memory Rank-1 Cuts (lm-R1Cs).
	\item \textbf{Strong Degree Cuts (SDCs)} proposed in \textcite{contardo2011, contardo2014},
	      are cutting planes which can be considered
	      a specialized version of the SCCs.
	      They can enforce partial route elementarity in the RMP formulation
	      and are redundant when the pricer always outputs elementary paths.
	      SDCs can be used to achieve the elementarity bound in the case
	      the pricer produces non-elementary routes \parencite{contardo2014}.
	\item \textbf{k-Cycle Elimination Cuts (k-CECs)}, proposed in \textcite{contardo2014},
	      are a weakened form of the SDCs, which forbids
	      routes that have cycles of length smaller or equal to $k$ over a customer $i \in V_0$.
	      SDCs may be viewed as a special case of k-CECs with $k = \infty$.
	      The k-CECs have less impact in the pricing problem compared to SDCs.
	\item \textbf{Clique inequalities} readjusted for the VRPTW problem domain in \textcite{spoorendonk2010clique}.
\end{enumerate}

For a more complete survey on the various non-robust cutting planes
proposed over the years for the CVRP refer to \textcite{costa2019}.

\section{Solving the Pricing Problem}
\label{sec:solving-the-pricing-problem}

The Pricing Problem (PP) asks for the determination of an elementary shortest path,
subject to resource constraints,
over a directed network formulation where the cost of each edge
is dualized.
In the ESPPRC problem, the elementarity condition imposes
that the optimal route may visit the same vertex at most once.
For convenience we define as \textit{Shortest Path Problem with Resource Constraints} (SPPRC)
as the non-elementary version of the ESPPRC and the abbreviation RCSP
to denote a \textit{resource constrained shortest path}.
Sometimes SPPRC is also abbreviated as RCSPP: \textit{Resource Constrained Shortest Path Problem}.
As it was claimed in \textcite{dror1994},
since the underlying network may contain negative cost cycles,
the ESPPRC is an NP-hard problem.

\medskip

The $q$-routes \parencite{christofides1981exact}
are routes $p$ with total resource consumption $q(p) \le Q$
that do not necessarily satisfy the elementarity condition and may thus contain cycles.
In the $q$-routes relaxation, each additional visit to already covered customers
counts toward the total resource consumption.
In the original definition of $q$-routes cycles of two vertices are prohibited.
The $q$-routes with $k$-cycle elimination
are a natural extension of the $q$-routes
in which multiple visits to the same vertex are allowed only
if at least $k$ other vertices are covered in between.

It was discovered that broadening the set of feasible paths $P$
in the SP formulation to include $q$-routes could result
in a more tractable pricing problem
by making it weakly NP-hard
and thus solvable via a pseudo-polynomial algorithm \parencite{desrochers1988, irnich2005}.
Notice that the $q$-routes violates the SP constraints
\labelcref{eq:set-partitioning-customers-visited-by-exactly-one-route},
thus, they won't be part of a CVRP optimal solution.
Many efficient algorithms for the VRP
rely on the solution of SPPRC subproblems which
make use of $q$-routes  \parencite{desrochers1992, fukasawa2006, contardo2011}.
While this expansion of the set of feasible paths $P$ is still valid,
it has the unfortunate side effect of yielding significantly
worse dual bounds for the linear relaxations \parencite{feillet2004}.
As a result,
the definition of the set of feasible paths $P$
is critical in balancing efficiency at the pricing stage
with the overall quality of the dual bounds.

The label-correcting algorithm was first proposed in \textcite{desrochers1992}
for solving an SPPRC pricing sub-problem induced from the Set Covering (SC) formulation of the VRPTW.
The label-correcting algorithm,
which could only generate $q$-routes at the time,
is a dynamic programming algorithm that works through
label construction, propagation, and correction from node to node.
Each partial path is tracked by the algorithm using labels.
Each label encodes the current partial resource consumption, among other things.
The algorithm’s dominance rules allow it to efficiently prune the search space
by ignoring dominated labels, thus vastly speeding up the resolution process.
The label-correcting algorithm is a natural extension of
the traditional Bellman-Ford algorithm \parencite{bellman1958, fordjr1956},
but it takes additional path constraints into account.
The Bellman-Ford algorithm is commonly known
by all operations research practitioners
and it is used to compute resource-unconstrained shortest paths
on a negative-cycles-free network.
The running time complexity of the label-correcting algorithm
for pricing $q$-routes is $O(N^2 Q)$ operations.
The number of processed labels scales with the vehicle capacity.
By nature of the approach,
the applicability of the labeling algorithm is limited to VRPs having stringent vehicle capacity
and characterized by routes visiting a mediocre amount of customers each \parencite{jepsen2008branchandcut}.

\textcite{feillet2004} extends the label-correcting algorithm
to handle elementary paths by introducing additional fictitious resources for each node.
As the authors point out, this new algorithm has two advantages.
First, the linear relaxation produces a significantly smaller duality gap than treating $q$-routes.
Second, it may allow for the resolution of certain problem classes
where relying on column generation schemes based on $q$-routes is hardly an option.
The extended algorithm of \citeauthor{feillet2004} for pricing elementary routes
has a running time complexity of $O(2^N Q)$ operations,
limiting its applicability to larger problems.
\textcite{righini2006} later improve the dynamic programming algorithm  of \citeauthor{feillet2004}.

Nonetheless, some improvements have been made to the overall running time
of the label-correcting algorithm for pricing elementary routes.
Some significant contributions in this domain can be attributed to:
(i) \textit{bidirectional search} proposed in \textcite{righini2006}
and (ii) \textit{decremental state-space relaxation} (DSSR) proposed independently in
\textcite{boland2006, righini2008} under different names.
The \textit{decremental state-space relaxation} (DSSR)
is an approach where elementarity impositions are included lazily
during the running time of the column generation phase.
In DSSR, the label-correcting algorithm
is first asked to generate $q$-routes, then for each vertex that is visited
twice or more, elementarity is enforced at the pricer stage
and the procedure is repeated.
The first BCP algorithm based on full elementarity routes
was proposed in \cite{chabrier2006}, but unfortunately,
applying arbitrary $k$-cycle elimination to the pricing problem
has not been thoroughly researched since.
Despite arbitrary $k$-cycle elimination can also
be enforced by using non-robust cuts (see discussion in \cref{sec:bap-cutting-planes}),
\citeauthor{feillet2004} demonstrated that avoiding such cycles
within the column generation procedure supplied
substantially better dual bounds at the cost
of increasing the running time of the pricing problem.

\medskip

Given the complexity of the ESPPRC,
many authors inspired by these works have investigated using
some form of controlled \textbf{partial elementarity} condition.
The idea behind partial elementarity is to obtain dual bounds
as close to the elementary route bound as possible
while still keeping the pricing problem manageable \parencite{contardo2015}.

\textcite{irnich2006, fukasawa2006} have investigated the usage of
$q$-routes with $k$-cycle elimination with $k \ge 3$ within the labeling algorithm.
\textcite{fukasawa2006} tests the $q$-routes with $4$-cycle elimination
and shows that such an approach leads to a substantially slower pricing problem
with dual bounds that are extremely far from the elementary bound.
Instead, \textcite{desaulniers2008} takes a totally different approach.
They introduce a new concept of "partial elementarity"
obtained by enforcing the elementarity condition
only on a small predetermined subset of customers.

The \textit{ng-routes relaxation} developed in \textcite{baldacci2011}
is credited as one of the radical innovations in modern pricing efficiency.
\citeauthor{baldacci2011} observed that in most cases,
$q$-routes cycles emerged to use only low-cost edges
and were confined to comparatively small clusters of the graph.
They define the concept of \textit{ng-set} $N_i$ for a vertex $i$
which encodes the $|N_i|$ closest neighbors of the vertex $i \in V$.
The quantities $|N i|$ can be increased on-demand to achieve better dual bounds,
but doing so leads to an exponential increase in pricing complexity.
The ng-sets can be determined a priori or dynamically, as shown in \textcite{roberti2014}.
The ng-routes permits cycles over a vertex $i \in V$ only if the route
passes through a vertex $j \in V \mid i \notin N_j$.
The new novel relaxation of \citeauthor{baldacci2011}
is simple to incorporate into the dynamic programming labeling algorithm.
Dominance is verified through a limited-memory set
that changes as the route get extended.
The limited memory, by its nature,
"forgets" old covered vertices,
which can then be subsequently revisited
as the generated path gets longer.
The ng-routes relaxation can be considered a more versatile and dynamic version
of $q$-routes with $k$-cycle elimination.
They use a different definition of cycle length.
This definition provides a better measure of a cycle's impact
and may be regarded as the primary cause of this relaxation's efficiency.
The ng-routes relaxation measures cycle lengths in terms of travel or time distances.
In contrast, in classical $k$-cycle relaxation,
they are measured in terms of customers visited \parencite{contardo2014}.
This new novel relaxation achieves a bound that is very close to the elementary bound
while not being detrimental to the pricing problem.
Furthermore, depending on the circumstances,
the amount of elementarity can be controlled by selecting the appropriate
neighborhood set size $|N i|$.

\medskip

We conclude this section by mentioning a few final contributions
that are related to the pricing problem.

\textcite{fukasawa2006} modifies the label-correcting algorithm
to employ it as a fast pricing heuristic.
Heuristics can significantly speed up the column generation process.
The invocation of the exact pricer occurs solely when the pricing heuristic
fails to determine a valid reduced-cost route.
\textcite{desaulniers2008, archetti2011} propose a meta-heuristic based on tabu search
to generate routes with a negative reduced cost.

\textcite{lozano2013} propose the \textit{pulse algorithm} to solve the SPPRC.
\textcite{lozano2016} extend the pulse algorithm to handle elementary paths.

\textcite{desaulniers2019} propose a new paradigm called \textit{selective pricing} for the ng-SPPRC.
The column generation procedure is preemptively aborted in selective pricing
if there is proof that no reduced-cost elementary routes exist,
regardless of whether the ng-SPPRC admits reduced-cost ng-routes.
This method allows for rejecting some non-elementary routes even when they are not dominated.

The dual variables $\pi \in R^N$ tend to oscillate from one CG iteration to the next
as the average number of customers per route $N / K$ increases,
slowing the convergence speed of the column generation algorithm \parencite{toth2014}.
As a result, some dual variable stabilization techniques were proposed to address this issue
and reduce the number of pricing iterations required by the column generation algorithm
(see \cite{dumerle1999, rousseau2007, pessoa2013, pessoa2018automation}).
For a general introductory discussion on column generation stabilization techniques, see \textcite{vanderbeck2005}.
When the SC formulation is used instead of the SP formulation,
the dual variables are typically more stable \parencite{rousseau2007, feillet2010}.

We conclude the section by mentioning additional surveys
discussing labeling algorithm for tackling the non-elementary SPPRC:
\textcite{irnich2005, pugliese2010, pugliese2013}.

\begin{comment}
// @NOTE(dparo): A useful note for myself. No need to be integrated in the thesis
\textcite{irnich2005}
4.1.1 Label Setting and Label Correcting Algorithms
The defining property of a
label setting algorithm is that those labels chosen to be extended (in the path extension step)
are kept until the end of the labeling process. They will not be identified as discardable in
subsequent calls of the dominance algorithm. Labeling algorithms that do not guarantee
this behavior are called label correcting algorithms. The general ideas of label setting as
well as label correcting algorithms in the context of the one-dimensional shortest path
problem (SPP) are, for instance, explained in the book of Ahuja et al. (1993).
\end{comment}
