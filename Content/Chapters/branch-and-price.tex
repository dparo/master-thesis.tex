\chapter{Branch and Price}
\label{sec:branch-and-price}

In this chapter, we will introduce
the branch-and-price (BAP) framework and the Column Generation (CG) approach,
two foundational components employed by contemporary CVRP solvers.
The focus of our presentation will be on these two critical components in the context of the CVRP.
Refer, instead, to \textcite{vanderbeck2005, lubbecke2005, desrosiers2011}
for a review on CG approaches to solve arbitrary MIP problems.
For a primer introduction to branch-and-price schemes refer to the work of \textcite{barnhart1998, desrosiers2005}.
We refer the reader to the work of \textcite{feillet2010}
which contains a helpful tutorial on CG and BAP algorithms specific to VRPs.

Branch-and-price (BAP) frameworks are in essence a branch-and-bound (BAB) scheme \parencite{land2010}
that originates when solving the SP/SC formulation (see \cref{sec:set-partitionining-formulation})
for VRPs.
BAB-based schemes employ a search tree and a pruning strategy
based on bounding the objective function to seek an optimal solution.
Compared to more traditional branch-and-cut (BAC) frameworks,
their primary focus is the usage of a Column Generation (CG) technique for improving the dual bound,
see \textcite{righini2008}.
BAP frameworks were first applied successfully to the Cutting Stock problem in \textcite{gilmore1961}.
The so-called branch-price-and-cut (BPC) extends the traditional BAP framework.
In the BPC framework,
additional cutting planes are added to strengthen the linear relaxations
associated with each node of the search tree
with the aim of further improving the dual bounds.

In the next section \cref{sec:column-generation-and-pricing-problem}
we will illustrate the column generation algorithm
and the pricing problem, two vital pieces in branch-and-price frameworks.

\section{Column generation and the Pricing Problem}
\label{sec:column-generation-and-pricing-problem}

Consider the \textbf{Master Problem} (MP) defined
as the linear relaxation of the SP formulation
\labelcref{eq:mp-obj-func,eq:mp-customers-visited-by-exactly-one-route,eq:mp-K-routes,eq:mp-lambda-mip-var-bounds}
obtained by relaxing the integrality constraints:
\begin{align}
	\min_{\lambda} \quad z_\mt{MP}(\lambda) & = \sum_{p \in P}  c_p \lambda_p \label{eq:mp-obj-func}                                                                                                                             \\
	                                        & \sum_{p \in P} \lambda_{p} = K\label{eq:mp-K-routes}                                                                                                                               \\
	                                        & \sum_{p \in P}  a_{ip} \lambda_p = 1                   & \quad \forall i \in V_0                                              \label{eq:mp-customers-visited-by-exactly-one-route} \\
	                                        & 0 \le \lambda_p \le 1                                  & \quad \forall p \in P \label{eq:mp-lambda-mip-var-bounds}.
\end{align}
The constraint $\lambda_p \le 1$ in \cref{eq:mp-lambda-mip-var-bounds}
is implied from \cref{eq:mp-customers-visited-by-exactly-one-route} and can thus be removed.
An optimal solution to the MP provides a valid dual bound at the root node of the search tree.
The master problem can be modified by adding cuts or branching constraints
to improve the obtained dual bounds.

The dual problem associated with
\labelcref{eq:mp-obj-func,eq:mp-customers-visited-by-exactly-one-route,eq:mp-K-routes,eq:mp-lambda-mip-var-bounds}
is:
\begin{align}
	\max_{\pi} \quad z_\mt{DMP}(\pi) & =  K \pi_0 + \sum_{i \in V_0} \pi_i \label{eq:dmp-obj-func}                                                       \\
	                                 & \pi_0 + \sum_{i \in V_0} a_{ip} \pi_i \le c_p               & \quad \forall p \in P \label{eq:dmp-constraint1}    \\
	                                 & \pi_0 \in \R                                                & \label{eq:dmp-constraint2}                          \\
	                                 & \pi_i \in \R                                                & \quad \forall i \in V_0 \label{eq:dmp-constraint3},
\end{align}
where $\pi_0 \in \R, \pi_i \in \R \quad \forall i \in V_0$ represents the dual variables
associated respectively with constraints \labelcref{eq:mp-K-routes,eq:mp-customers-visited-by-exactly-one-route}.
In case the SC formulation
\labelcref{eq:set-covering-obj-func,eq:set-covering-K-routes,eq:set-covering-customers-visited-by-exactly-one-route,eq:set-covering-lambda-mip-var-bounds}
is used to define the MP,
\cref{eq:dmp-constraint3} in
\labelcref{eq:dmp-obj-func,eq:dmp-constraint1,eq:dmp-constraint2,eq:dmp-constraint3}
can be replaced in favor of $\pi_i \ge 0 \quad \forall i \in V_0$,
thus reducing the dual solution space.

When solving the MP,
at each iteration of the \textit{simplex algorithm} \parencite{dantzig1955}
we seek a non-basic variable, also called column,
to price out and enter the basis.
This is achieved by evaluating the dual variables $\pi \in \R^N$.
The dual variables $\pi \in \R^{N}$ are computationally intractable to evaluate
due to the enormous size of the set of routes $P$.

\medskip

Therefore, in BAP frameworks we consider only a small subset of columns $\mcP \subseteq P$,
obtaining the following linear program:
\begin{align}
	\min_{\lambda} \quad z_\mt{RMP}(\lambda) & = \sum_{p \in \mcP}  c_p \lambda_p \label{eq:rmp-obj-func}                                                                                                                              \\
	                                         & \sum_{p \in \mcP} \lambda_{p} = K\label{eq:rmp-K-routes}                                                                                                                                \\
	                                         & \sum_{p \in \mcP}  a_{ip} \lambda_p = 1                    & \quad \forall i \in V_0                                              \label{eq:rmp-customers-visited-by-exactly-one-route} \\
	                                         & \lambda_p \ge 0                                            & \quad \forall p \in \mcP \label{eq:rmp-lambda-mip-var-bounds},
\end{align}
which takes the name of \textbf{Restricted Master Problem} (RMP).

In BAP frameworks, we seek for a column to enter the basis.
This in turn requires solving the following sub-problem:
\begin{equation}\label{eq:pp-problem}
	{c^\star_p} = \min_{p \in P} \Set*{ \bar{c}_p = \sum_{e = \Set*{i, j} \in E} \Expr*{c_{e} - \frac{\pi_i + \pi_j}{2}} a_{ep}  },
\end{equation}
which takes the famous name of \textbf{Pricing Problem} (PP).
In \labelcref{eq:pp-problem}, $\bar{c}_p$ denotes the reduced cost of a route $p \in P$
and $c^\star_p$ is the reduced cost of the optimal route $p^\star \in P$
that leads to the best dual bound improvement.
Notice that $\bar{c}_p$ can also be expressed as $\bar{c}_p = c_p - \pi_0 - \sum_{i \in V_0} \pi_i a_{ip}$.
For convenience,
we define $\bar{c}_{e} = c_{e} - \frac{\pi_i + \pi_j}{2}$
as the reduced cost of an edge $e\in E$.

Any $p \in P$ which satisfies $\bar{c}_p < 0$ is a valid column which can enter the basis of the RMP.
The BAP solver must intelligently manage the set $\mcP \subseteq P$ that it stores within a pool.
During the resolution process, the BAP framework manages which routes to keep or drop from $\mcP$.
Because the set $\mcP$ is generally sparse,
any $p \in \mcP \mid \lambda_p = 0$ is a valid candidate to be dropped from the pool.
A BAP framework must be appropriately engineered to maintain
the size of the pool $\mcP \subseteq P$ manageable.

\medskip

In the literature, the resolution method, or algorithm,
used to solve the PP is known as \textbf{oracle} or \textbf{pricer}.
The oracle needs to solve the pricing sub-problem which, due to the definition of the set $P$,
coincides with solving an Elementary Shortest Path Problem with Resource Constraints (ESPPRC)
over a \textbf{new directed symmetric} network with weights
$\bar{c}_{ij} = c_{ij} - \frac{1}{2} \pi_i - \frac{1}{2} \pi_j$.
Resources are monotonically increasing quantities,
such as capacity or time,
which restrict the feasibility of a route.
The ESPPRC asks for an elementary route
connecting a \textit{source vertex} and a \textit{sink vertex}
that satisfies the resource consumption bounds.
Because of the elementarity condition, the route can only visit each vertex at most once.
In the ESPPRC, the depot node is split into two vertices (one source, one sink)
and the newly obtained network is characterized by $N + 1$ vertices.

\medskip

The column generation (CG) is an iterative algorithm,
successfully applied to a wide variety of problems \parencite{desrosiers2005},
which alternates between two phases \parencite{desaulniers2018}:
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}

	\item The simplex algorithm for solving the RMP, which is characterized by one or more pivot operations.
	\item One or several iterations of the Pricing Problem (PP) solved by invoking the pricer algorithm.
	      The simplex algorithm invokes the pricer to verify whether other pivot operations
	      can be performed for improving the dual bound.
	      The pricer algorithm usually lives in a separate external code module from the branch-and-price code.
\end{enumerate}

The column generation may also be interpreted
as a cutting-plane strategy for the dual problem.
The column generation procedure stops mainly under two scenarios:
(i) when no more negative reduced cost routes exist,
i.e. the PP outputs a $p^\star in P$ achieving $c^\star_p \ge 0$,
(ii) the CG procedure tails off,
i.e. the gained dual bound improvements
compared to the running time to generate a column
become suboptimal (optional).

If after the column generation procedure
the candidate solution to the RMP $\lambda^*$ satisfies the integrality constraints,
$\lambda^\star_p \in \Set*{0, 1} \quad \forall p \in \mcP$,
no branching or cutting planes are required
and the candidate solution $\lambda^*$ can update the incumbent.
If, instead,
$\exists p \in \mcP \mid \lambda^\star_p \notin \Set*{0, 1}$
then a branching strategy is usually necessary
to seek the best integral solution.
When all the nodes of the branch-and-bound tree have been explored or pruned,
then the CVRP problem is solved to optimality
and the incumbent solution becomes the optimal solution
$(p_1, \dots, p_K) \mid \lambda^\star_{p_i} = 1$.

\medskip

It's also worth noting that
the CG doesn't have to solve the PP optimally
every time the simplex algorithm advances.
Finding any $p \in P$ that achieves $\bar{c}_p < 0$ is usually enough to improve the dual bound.
Except for proving the optimality at the last CG iteration,
there is commonly no need to solve the pricing problem exactly.
Therefore, fast and efficient heuristic algorithms may be employed
to tackle the pricing problem,
especially during the very first few pricing iterations,
where finding reduced cost columns is effortless.

\section{Branching, Route Enumeration and Cut Generation}
\label{sec:branching-and-cut-generation-within-bap-frameworks}

In order to satisfy the integrality constraints for the SP formulation,
solving the RMP at the root node is almost always not enough.
The CG algorithm may in fact terminate with a non-zero duality gap.
Therefore,
a search tree and a branching scheme is employed
to seek for the optimal integral solution $\lambda^\star_p \in \Set*{0, 1} \quad \forall p \in P$.

Although non strictly-necessary, modern BAP also use
cut generation procedures to efficiently improve the dual bound and the convergence speed.
Modern BAP frameworks
are in fact a hybridization between a BAP and a BAC framework,
making them a branch-price-and-cut (BPC) frameworks.
Some notable works integrating cutting planes and proposing
a BCP approach for the VRP can be found \textcite{fukasawa2006, ropke2012}.
Refer to \textcite{sadykov2019modern} for a discussion of the state-of-the-art
components that are part of modern branch-and-price frameworks.

\medskip

It is important to note however that branching is not a strictly required operation.
Route enumeration is another technique that can be used in place of branching
for obtaining integral solutions which was first proposed for the CVRP in \textcite{baldacci2008}.
In route enumeration, all elementary routes that may belong to the VRP optimal solution are enumerated,
and an SP formulation containing all these enumerated routes are solved through a MIP.
Route enumeration is obtained through a labeling algorithm similar to the one employed in the pricing problems.
The problem of this approach is the possibly huge number of routes that needs to be enumerated,
and this quantity is highly linked to the tightness of the duality gap,
and with the average length of a tour $N / K$.
Route enumeration is an operation that takes exponential space complexity,
but it can drastically improve the performance of the BPC on some instances.
The major contributions employing route enumeration in place of branching can be found in
\textcite{baldacci2008,baldacci2011}.

Modern BPC frameworks instead take a hybrid approach by combining branching and route enumeration
(see \cite{pessoa2008, pessoa2009,contardo2014,pecin2017improved,pecin2017new,pessoa2020}).
After the convergence of the column generation, route enumeration is attempted.
If the number of enumerated routes starts to exceed a maximum limit, enumeration
is preemptively aborted and conventional branching is applied.
Once the primal-dual bound gap $\bar{z} - \ubar{z}$ reaches desirable levels, the route enumeration
procedure will enumerate all routes under the maximum limit.
At the point the associated RMP formulation can be solved efficiently through a MIP.

We will not concentrate much of our attention on route enumeration in this
thesis, since their presence doesn't influence the pricing problem.
Nonetheless, it's important to know about its existence and role within
the branch-and-price frameworks.

\medskip

Branching and cut generation in BCP frameworks are more delicate operations
compared to more traditional BAC frameworks due to the presence of the pricing problem.
As classified in \textcite{dearagao2003},
depending on the branching and cut generation schemes employed,
two classes of inequalities are possible:
\textbf{robust} versus \textbf{non-robust} inequalities.

A \textbf{robust} inequality is an inequality
which can be safely added to the RMP
without altering the structure of the set of feasible paths $P$ \parencite{fukasawa2006}.
That is,
robust inequalities do not require explicit modeling in the PP formulation
and instead manifest their contribution directly in the reduced cost edges $\bar{c}_e$.
An oracle, therefore,
after the introduction of a robust inequality in the RMP,
needs to solve the same ESPPRC problem but with slightly different weights associated on each edge.

A \textbf{non-robust} inequality, instead,
is much harder to handle since it changes the structure of the set of feasible paths $P$.
Non-robust inequalities may in general have great potential at reducing the integrality gap
but,
unfortunately, require explicit modeling and support from the oracle.
These types of inequalities can drastically complicate the pricing problem,
trading better dual bound improvements for increased column generation times.
Therefore, their usage must be assessed on a case-by-case basis \parencite{desaulniers2011}.
Non-robust inequalities may present themselves both in the branching and cut-generation phases.

In this thesis
we will mostly concentrate on branching and cut generation schemes
which make use of \textbf{robust} inequalities.
Refer to \textcite{desaulniers2011} for an introduction in cutting planes for BAP algorithms.

\begin{comment}
\textcite{lubbecke2005}
The purpose of the RMP (as is the purpose of subgradient algorithms in Lagrangian relaxation) is to
provide dual variables: To be transferred to the subproblem, and to control our stopping criterion. In
the end only, we have to recover from the RMP a primal feasible solution to the compact formulation.
Primal methods, like column generation, maintain primal feasibility and work towards dual feasi-
bility. It is therefore only natural to monitor the dual solution in the course of the algorithm. In our
opinion, the dual point of view reveals most valuable insight into the algorithm’s functioning. We call
the polyhedron associated with the dual of the RMP the dual polyhedron. A dual solution to the RMP
needs not be unique, e.g., if the primal is degenerate. This is significant inasmuch the dual solution di-
rectly influences the selection of new columns. Since a dual basic solution corresponds to an extreme
point of the optimal face, it may be a bad representative of all the dual solutions obtainable.
\end{comment}

\subsection{Branching}
\label{sec:bap-branching}

In this section we will introduce branching for the SP formulation,
under the assumption that a branch-and-price scheme is employed
for solving the CVRP.

At first glance,
it might seem reasonable to branch directly on the $\lambda_p$ variables of the SP formulation.
Unfortunately, such form of branching has two main problems \parencite{vanderbeck2010reformulation}.
First, it is non-robust and leads to a harder pricing problem: an ESPPRC with forbidden paths \parencite{villeneuve2005}.
Second, it produces a highly unbalanced tree.

Most of the branching approaches studied in the literature for the CVRP involve
mere extension of branching schemes used traditionally for the TSP.
In fact, one of the most simple branching scheme,
yet one of the most effective,
involves \textbf{branching on edges}.
The branching on edges scheme was first proposed for the CVRP in \textcite{christofides1969},
and later re-adapted in different forms in \textcite{fisher1994, miller1995}.
The arc flows can be easily computed from the master problem as:

\begin{equation}
	x_e = \sum_{p \in P} a_{ep} \lambda_p  \quad \forall e \in E
\end{equation}

where $a_{ep}$ represents the number of times route $p \in P$ crossed edge $e \in E$.

Given a candidate fractional solution $\lambda^\star_p \quad \forall p \in \mcP$
and a valid edge $e$ to branch on, $e \mid x_e \notin \Set*{0, 1, 2}$,
it is possible to generate two descendant nodes in the search tree
to continue scanning for integral solutions:

\begin{equation}\label{eq:sp-branching-on-arcs}
	x_e \le \floor*{\sum_{p \in \mcP} a_{ep} \lambda^\star_p}, \quad
	x_e > \ceil*{\sum_{p \in \mcP} a_{ep} \lambda^\star_p}
\end{equation}

Branching on arcs is an approach which is both: extremely simple and robust.
Let $\omega_e \in \R$ represent the dual variable associated to
edge $e \in E$ and to
one of the branching polarity in \cref{eq:sp-branching-on-arcs},
then, after branching,
the new reduced cost $\bar{c}_e$ for an arc $e \in E$ becomes:

\begin{equation}
	\bar{c}_e = c_e - \frac{\pi_i + \pi_j}{2} - \omega_e
\end{equation}

where again $\pi \in \R^N$ represents the dual variables associated with \cref{eq:mp-K-routes,eq:mp-customers-visited-by-exactly-one-route}.

Branching on edges has the disadvantage of achieving only local changes
to the fractional solution.
For this reason, \textcite{augerat1998} propose an
approach to obtain larger perturbations.
They achieve this by branching on Rounded Capacity Constraints (RCCs) defined over
an arbitrary set $S \subseteq V_0$ with two descendant nodes:
\begin{equation}\label{eq:sp-branching-on-cutsets}
	\sum_{e \in \delta(S)}x_e \le 2 r(S), \quad
	\sum_{e \in \delta(S)}x_e \ge 2 r(S) + 2
\end{equation}
\textcite{pecin2017improved} apply a similar branching approach.

\textit{Ryan and Foster branching} \parencite{ryan1981integer} is another possible branching rule.
This non-robust branching rule makes the pricing sub-problem much harder,
but it has the main benefit to lead to more balanced search trees.
\textit{Branching over the accumulated resource consumption}, proposed in \textcite{gelinas1995new},
is another commonly employed branching rule, which has the main benefit of not complicating
the pricing difficulty.

\textit{Strong branching}, a commonly employed branching technique,
evaluates each possible branching candidates
by measuring their impact based on some scoring function.
The idea is to select either the branching candidate that
would heuristically lead to the best dual bound improvement
or that it is heuristically known to lead to a more balanced search tree.
Strong branching can reduce the size of the search tree
at the expense of a slower branching candidate evaluation.
\textcite{fukasawa2006, pecin2017limited, pecin2017new} applied strong branching
to the vehicle routing problems.

\medskip

Reduction rules may be employed to remove some arcs
which can be proved to not belong to an optimal solution.
\textit{Variable fixing} may be used as a reduction rule by exploiting
the usage of a dual bound $\bar{z}$ and primal bound $\ubar{z}$ to eliminate some
arcs $e \in E \mid \hat{c_e} \ge \bar{z} - \ubar{z}$ \parencite{hadjar2006, irnich2010}.
Reduction rules may be viewed as a special case of branching
with a single descendant node.
Reducing the set of edges to consider may filter a good portion of the search-space.

\subsection{Families of Cuts}
\label{sec:families-of-cuts}

In this section we will introduce the families of inequalities
which can be used for cut generation for respectively
the two-index vehicle flow formulation
and the SP formulation.

While the 2F formulation is not the primary focus of this thesis,
presenting and studying valid inequalities for such formulation
will be important for the sub-problem induced in the column generation phase.
In fact, many 2F valid inequalities, if properly reformulated
can be applied to the ESPPRC.
The very few first attempts in proposing valid inequalities
to improve the linear relaxation for the 2F were obtained by
generalizing the constraints for the traditional TSP problem, see \textcite{naddef1993}.
\citeauthor{naddef1993} showed that its is possible to re-adapt
every valid inequality obtained for the TSP to the CVRP,
by putting them into a proper tight triangular form.
As an example,
the comb inequalities were re-adapted from the TSP to the CVRP \parencite{chvatal1973,grotschel1979,augerat1995approche}.

Families of valid inequalities for the 2F CVRP formulation
can be separated in different families \parencite{toth2014}.
We highlight two main families: the capacity constraints and the multistar inequalities.

The \textbf{capacity constraints} are inequalities which can be expressed in the form
$\sum_{e \in \delta(S)} x_e \ge 2 r(S) \quad \forall S \subseteq V_0, |S| \ge 2$.
Depending on how $r(S)$ is computed, this set of constraints take different names.
If $r(S) = \sum_{i \in S} q_i / Q$, we obtain the so-called Fractional Capacity Constraints (FCC).
Instead, if we use the typical Bin Packing Problem (BPP) lower bound, $r(S) = \ceil*{\sum_{i \in S} q_i / Q}$, we obtain the so-called Rounded Capacity Constraints (RCC).
The RCC were first presented in \textcite{laporte1983} for the CVRP 2F formulation.

The \textbf{multistar inequalities} were initially proposed in \textcite{araque1990} for the CVRP with unit demands,
extended to the generic CVRP in \textcite{gouveia1995, achuthan1998},
and later generalized in the so called Generalized Large Multistart (GLM) for the CVRP in \textcite{letchford2002,letchford2006}.
Given two disjoint sets of customers $A, B \subseteq V_0 \mid A \cap B = \emptyset$,
and $\alpha, \beta, \gamma \in \R$,
a multistar inequality is described in the 2F formulation through a
template of the form:

\begin{equation}
	\alpha \sum_{e \in E(A)} x_e + \beta \sum_{e \in \Expr*{\delta(A) \cap \delta(B)}} x_e \le \gamma
\end{equation}

The multistar inequality were first applied successfully within a branch-and-cut framework
in \textcite{araqueg1994}.
\textcite{letchford2006} proves that GLMs are implied by the SP model,
even if the set of feasible paths $P$ is relaxed to contain non-elementary routes.

\medskip

We will terminate the remainder of this section with the introduction
of the families of inequalities which can be used for cut generation
for the SP formulation.
Despite the SP formulation generally provides better dual bounds
compared to other CVRP formulations,
these bounds may still be too weak to obtain an efficient algorithm.
Thus, it is common practice to introduce cutting-plane approaches
in modern branch-and-price based VRP solvers.

Cutting-planes involving arc-flow variables only, are by nature
robust.
Since the RCC inequalities involve only the edges $e \in E$ crossing a set $s \subseteq V_0,\ |S| \ge 2$,
they can trivially be extended to a robust inequality for the SP formulation:

\begin{equation}
	\sum_{p \in P} \sum_{e \in \delta(S)}  a_{ep} \lambda_p \ge r(S)
\end{equation}

where $\sum_{e \in \delta(S)} a_{ep}$ counts the number of times a route $p \in P$
enters or leaves a set $S$ and $r(S)$ represents the number of truck needed
to serve each customer $i \in S$.
\textcite{lysgaard2003cvrpsep} proposes a heuristic procedure implementation
for efficiently separating the RCC inequalities.

\medskip

Robust cuts are quite effective at closing the integrality gap, but alone may not
be sufficient for some harder VRP instances,
therefore some researchers tried to apply non-robust cuts to the CVRP with good success.
In order to use them effectively, their separation must be carefully
planned out, by taking into account the aggravation of the pricing problem.
While in this thesis we will mostly avoid this type of inequalities,
it is nonetheless important to acknowledge and understand their contributions.
Non-robust cuts have been traditionally handled by extending the
dynamic programming labeling algorithm
through the addition of fictitious resources and through modifications to the dominance rules.

\medskip

Major contributions in the non-robust cutting planes domain are:

\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}

	\item \textbf{Strong/Strengthened Capacity Cuts (SCCs)} proposed in \textcite{baldacci2008},
	      which can be considered a non-robust tighter version of the RCCs.
	      Compared to RCCs, they are not affected by routes entering set $S \subseteq V_0$ more than once.
	\item \textbf{Extended Capacity Cuts (ECCs)} proposed in \textcite{pessoa2008, pessoa2009}
	      are another proposed generalization of the RCCs.
	\item \textbf{Subset Row Cuts (SRCs)} proposed in \textcite{jepsen2008subsetrow}, a non-robust
	      inequality obtained as a subset of the  Chv\'atal-Gomory rank-1 cuts \parencite{chvatal1973}
	      applied to a subset $C \subseteq V_0$ of customers.
	      Their separation is NP-hard.
	      Therefore, Typically the subset $C$ is separated through enumeration
	      and for computational tractability and restricting the evaluation $\forall C \subseteq V_0 \mid |C| \le 5$.
	      3-SRCs, namely SRCs where $|C| = 3$, were applied successfully in many works \parencite{desaulniers2008, jepsen2011, baldacci2011, contardo2014, pecin2017improved}.
	      The SRCs were later generalized to a more general Chv\'atal-Gomory Rank-1 cuts (R1Cs) in \textcite{petersen2008}.
	      R1Cs are potentially very strong, but they make the pricing subproblems significantly harder.
	      \textcite{baldacci2011} proposes a weakened variant of the 3-SRCs inequalities.
	\item \textbf{Limited Memory Subset Row Cuts (lm-SRCs)} proposed in \textcite{pecin2017improved},
	      are a dynamically controlled weakening of the SRCs that leads far less impact to
	      the PP.
	      Later, \textcite{pecin2017limited} extends this concept to the Limited Memory Rank-1 Cuts (lm-R1Cs).
	\item \textbf{Strong Degree Cuts (SDCs)} proposed in \textcite{contardo2011, contardo2014}, they can be considered
	      a specialized version of the SCCs.
	      They can enforce partial route elementarity in the RMP formulation
	      and are redundant when the pricer always outputs elementary paths.
	      SDCs can be used to achieve the elementarity bound in the case
	      the pricer produces 1non-elementary routes \parencite{contardo2014}.
	\item \textbf{k-Cycle Elimination Cuts (k-CECs)}, proposed in \textcite{contardo2014},
	      are a weakened form of the SDCs, which forbids
	      routes that have cycles of length smaller or equal to $k$ over a customer $i \in V_0$.
	      SDCs may be viewed as a special case of k-CECs where $k = \infty$.
	      The k-CECs have less impact in the pricing problem compared to SDCs.
	\item \textbf{Clique inequalities} readjusted for the VRPTW problem domain in \textcite{spoorendonk2010clique}.
\end{enumerate}

For more details about cutting planes in BPC frameworks,
refer to \textcite{desaulniers2011}.
For a more complete survey on the various non-robust cutting planes
proposed over the years for the CVRP refer to \textcite{costa2019}.

\section{Solving the Pricing Problem}
\label{sec:solving-the-pricing-problem}

The Pricing Problem (PP) asks for the determination of an elementary shortest path,
subject to resource constraints,
over a directed network formulation where the cost of each edge
is dualized.
In the ESPPRC problem, the elementarity condition imposes
that the optimal route may visit the same vertex at most once.
As it was claimed in \textcite{dror1994},
since the underlying network may contain negative cost cycles,
the ESPPRC is an NP-hard problem.

\medskip

The $q$-routes \parencite{christofides1981exact}
are routes $p$ with total resource consumption $q(p) \le Q$
that do not necessarily satisfy the elementarity condition and may thus contain cycles.
In $q$-routes each additional visit to already covered customers
stills counts to the total consumption of the resource.
In the original definition of $q$-routes cycles of two vertices are prohibited.
The $q$-routes with $k$-cycle elimination
are a natural extension of the $q$-routes
in which multiple visits to the same vertex are allowed only
if at least $k$ other vertices are covered in between.

It was observed that extending the set of feasible paths $P$ in
the SP formulation to include also the q-routes could lead to a
more tractable pricing problem, by making it weakly NP-hard
and thus solvable through a pseudo-polynomial algorithm \parencite{desrochers1988, irnich2005}.
Notice that the q-routes violates the SP constraint of \cref{eq:set-partitioning-customers-visited-by-exactly-one-route},
thus, they won't be part of a CVRP optimal solution.
Many efficient algorithms for the VRP
rely on the solution of SPPRC subproblems which
make use of q-routes  \parencite{desrochers1992, feillet2004, fukasawa2006,contardo2011}.
This enlargement of the set of feasible paths $P$,
while still valid,
it has the unfortunate downside
of obtaining significantly worse dual bounds for the linear relaxations \parencite{feillet2004}.
Therefore, the choice for the set of feasible paths $P$ plays an important
role in trading off efficiency at the pricing stage with
overall quality of the dual bounds.

The label-correcting algorithm was first proposed in \textcite{desrochers1992}
for the VRPTW Set Covering (SC) formulation
to tackle the pricing problem modeled through a SPPRC.
The label-correcting algorithm, which at the time was able to generate only q-routes,
is a dynamic programming algorithm
which works by label construction, propagation and correction from node to node.
The principle of this algorithm is to associate with each possible partial
path a label indicating the current resource consumption over the path.
The dominance rules in the label-correcting algorithm allows
to efficiently prune the search space by ignoring dominated labels, thus speeding
up the resolution process tremendously.
The label-correcting algorithm
is a natural extension of the Bellman-Ford algorithm \parencite{bellman1958, fordjr1956},
a common algorithm present in the "tool belt" of all operations research practitioners.
Its running time complexity for pricing q-routes is $O(N^2 Q)$ operations.
The label-correcting algorithm tends to have shortcomings when the
produced routes visit a high number of nodes,
i.e. when the vehicle capacity is not particularly stringent.
This results in a large amount of processed labels that require processing \parencite{jepsen2008branchandcut}.

The label-correcting algorithm, was later extended to handle
elementary paths in \textcite{feillet2004},
where they propose using an additional resource for each node
to handle the elementarity condition.
As the authors point out, this new algorithm has a two-fold benefit.
First, the duality gap obtained at the linear relaxation is substantially better
compared to considering just the q-routes.
Second, it might enable certain classes of problems where relying
on column generation schemes based on q-routes is simply not an option.
The running time complexity of the new extended algorithm for pricing elementary routes
is $O(2^N Q)$ operations,
thus limiting its applicability on bigger problems.
Later, \textcite{righini2006} improves the dynamic programming
algorithm for pricing elementary routes.

Nonetheless, some contributions have been made to improve its overall running time.
Some major ones can be attributed to:
(i) bidirectional search proposed in \textcite{righini2006},
(ii) decremental state space relaxation (DSSR) proposed independently in
\textcite{boland2006, righini2008} under different names.
The decremental state space relaxation is an iterative
approach where elementarity is iteratively inserted on demand.
In this approach the label-correcting algorithms
is first asked to generate q-routes, then for each vertex that is visited
twice or more, elementarity is enforced at the pricer stage
and the procedure is repeated.
The first BCP algorithm, using full elementarity routes
was proposed in \cite{chabrier2006}, but unfortunately,
applying arbitrary $k$-cycle elimination to the pricing problem,
have since not been studied in more depth.

\medskip

Despite arbitrary $k$-cycle elimination can also
be enforced through the usage of non-robust cuts,
\citeauthor{feillet2004} showed that their elimination
within the column generation procedure supplied
substantially better dual bounds at the cost
of increasing the running time of the pricing problem.
Inspired from these works, given the complexity
of the ESPPRC, many authors have investigated the usage
of a controlled \textbf{partial elementarity} condition.
The idea of partial elementarity consists in obtaining
dual bounds as close as possible to the elementary route bound,
while still keeping the pricing problem manageable \parencite{contardo2015}.

Initial efforts, have studied the usage of $q$-routes with
$k$-cycle elimination with $k \ge 3$ within the labeling algorithm \parencite{irnich2006, fukasawa2006}.
\textcite{fukasawa2006} test the $q$-routes with $4$-cycle elimination
and they show that such an approach leads
to a very slow pricing problem while
producing dual bounds very far from the elementary bound.
\textcite{desaulniers2008}, instead, take a different approach.
They introduce a custom concept of "partial elementarity"
which is achieved by enforcing the elementarity condition
only to a small predetermined subset of the customers.

One of the major innovations in the contemporary pricing efficiency
can be attributed to the ng-routes relaxation developed in \textcite{baldacci2011}.
\citeauthor{baldacci2011} noticed that in most of the cases,
$q$-routes cycles appeared to use only edges of small costs
and were confined into relatively small clusters of the graph.
They define the concept of ng-set $N_i$ for a vertex $i$
which encodes the $|N_i|$ closest neighbors of the vertex $i \in V$.
The quantities $|N_i|$ may be raised on demand to achieve better dual bounds,
but it has to be noted that raising them lead to an exponential increase in complexity
in the pricing.
The ng-sets may be determined a priori but also dynamically as it is done in \textcite{roberti2014}.
The ng-routes allows cycles over a vertex $i \in V$ only if the route
passes through a vertex $j \in V \mid i \notin N_j$.
In the ng-routes relaxation,
dominance is verified through the usage of a limited-memory set
that changes as the route gets extended.
The limited memory, by its nature,
"forgets" old covered vertices,
which may then be subsequently revisited
as the generated path lengthens.
This new novel relaxation can be easily incorporated within the
dynamic programming labeling algorithm.
The ng-routes relaxation may be seen
as a more versatile, and more dynamic form of $q$-routes
with $k$-cycle elimination.
They employ a different definition of the cycles' length.
This definition provides a better measure of a cycle's impact,
and may be regarded as the main culprit of the efficiency of
this relaxation.
In ng-routes cycles's length are measured in terms of distances,
whereas in the $k$-cycle elimination they're measured
in terms of customers \parencite{contardo2014}.
This novel relaxation achieves a bound very close to the elementary bound while
not being detrimental for the pricing problem.
On top of that, one can control
the amount of elementarity by choosing the appropriate neighborhood set size $|N_i|$
value  depending on the circumstances.

\begin{comment}
\parencite{condardo2014}
Irnich and Villeneuve [15] used this observation to develop the so-called SPPRC
with k-cycle elimination (k-cyc-SPPRC),
in which short cycles
(in terms of the number of customers visited between two consecutive appearances of a given node)
are forbidden whereas long cycles (in terms of the same number) are still allowed.
The advantage of the ng-SPPRC with respect to k-cyc-SPPRC is how the length of a cycle is defined.
Indeed, the number of
customers between two appearances of a node may not be the right criterion,
the length of the cycle in terms of distance
being a better measure of the impact of a cycle in the linear relaxation lower bound.
The ng-SPPRC thus forbids cycles that
are short with respect to the time consumption regardless of
the number of nodes between two appearances of a given customer.
\end{comment}

\medskip

We conclude this section by mentioning other contributions
which are linked with the pricing problem.

\textcite{fukasawa2006} modify the label-correcting
algorithm to employ it as a fast pricing heuristic.
Heuristics can substantially improve the speed of the column generation process
as the exact pricing stage is called only when the pricing heuristic
fails at determining a valid reduced cost route.
\textcite{desaulniers2008} and \textcite{archetti2011} propose a tabu search
meta-heuristic approach to generate routes with negative reduced costs.

\textcite{lozano2013} proposes the so-called pulse algorithm
to solve the SPPRC, and in \textcite{lozano2016} the pulse algorithm
is extended to handle elementary paths.

\textcite{desaulniers2019} propose a new paradigm called \textit{selective pricing},
where they propose an early abortion of the column generation procedure,
when there's proof that no reduced-cost elementary routes,
even if the relaxed ESPRCC still admits reduced-cost relaxed routes.
This approach allows to discard some non-elementary routes
in the labeling algorithm even if they are not dominated.

It has been empirically seen that
as the average number of customers per route $N / K$ increases,
the dual variables $\pi \in R^N$ tend to oscillate from one iteration to another,
hurting the convergence speed of the column generation algorithm \parencite{toth2014}.
Therefore, some dual variables stabilization techniques
have been proposed to fix this problem and
to reduce the number of pricing iterations required
by the column generation algorithm (see \cite{dumerle1999, rousseau2007, pessoa2013, pessoa2018automation}).
Refer to \textcite{vanderbeck2005} for a general introductory
discussion on stabilization techniques for column generation.
Also employing the SC formulation in place of the SP formulation,
the dual variables have been shown to be typically more stable \parencite{rousseau2007, feillet2010}.

We conclude the section by pointing out two additional surveys
that discuss the labeling algorithm for solving the Shortest Path
Problem with Resource Constraints (SPPRC): references \textcite{irnich2005, pugliese2010, pugliese2013}.
