\chapter{Results}
\label{sec:results}

This chapter will present the empirical results
of the branch-and-cut algorithm,
whose implementation was discussed in \cref{sec:implementation-chapter}.
We will evaluate its performance as a pricer for the CVRP,
by comparing it with
the state-of-the-art labeling algorithm based on dynamic programming
discussed in the works of \textcite{pessoa2020generic, sadykov2021bucket}.

\medskip

\section{CVRP Benchmark Instances}
\label{sec:results-benchmark-instances}

Several CVRP benchmark instances are mandated to measure the competitiveness
of our branch-an-cut pricer in an accurate manner.
The \urlref{http://vrp.galgos.inf.puc-rio.br/index.php/en/}{CVRPLIB website}
is an online database for the vehicle routing problem that includes
several downloadable test instances for free, among other things.
It is a valuable resource for all practitioners interested in the VRP.
It includes interactive plots of various routing problem instances
and the optimal (or best known) solution discovered by the best scholars over time.
Each CVRP test instance is stored in a file with the following filename template:
\begin{center}
	\begin{LVerbatim}
		<F>-n<N>-k<K>.vrp
	\end{LVerbatim}
\end{center}
where \texttt{.vrp} is the file extension,
\texttt{<N>} is the number of vertices in the instance, and
\texttt{<K>} is the number of (maximum or exact) available vehicles.
Finally, \texttt{<F>} represents the set instance family.
\texttt{<F>} is a single letter that uniquely identifies the instance
set and the authors who published such a set.
\texttt{P-n40-k5.vrp} , for example, denotes a test instance made up
of $40$ nodes ($39$ customers) and $5$ vehicles.
The \texttt{P} in the name refers to the instance set family,
which was published in \textcite{augerat1995}.

Each CVRP instance file's contents adhere
to the \texttt{TSPLIB95} file format \parencite{reinelt1995}.
Distances between pairs of nodes are computed
using the 2D Euclidean distance function rounded to the nearest integer,
as became standard for the TSP in \textcite{reinelt1991}.
Rounding is performed to stabilize the optimal values,
allowing for an accurate comparison of different contributions.
However, rounding introduces issues when comparing heuristic contributions;
for more information, see \textcite{uchoa2017}.

\medskip

We used some of the most historic and well-known CVRP instances to evaluate the performance of our pricer:
set A, B, P \parencite{augerat1995},
set E \parencite{dantzig1959, christofides1969, gaskell1967bases, gillett1974heuristic},
set F \parencite{fisher1994}
and finally set M \parencite{christofides1979vehicle}.
If the reader is wondering how these test sets were generated in the first place,
they can consult the CVRPLIB website or the work of \textcite{uchoa2017}.

The employed test instances are summarized in
\cref{table:cvrp-instance-family-E,table:cvrp-instance-family-F,table:cvrp-instance-family-A,table:cvrp-instance-family-B,table:cvrp-instance-family-P}.

\input{Content/Chapters/Include/employed-cvrp-instance-tables.tex}

\subsection{Inflation of the CVRP Test Instances}
\label{sec:inflation-of-the-cvrp-test-instances}

We created new artificial instances based on the presented sets in
\cref{table:cvrp-instance-family-E,table:cvrp-instance-family-F,table:cvrp-instance-family-A,table:cvrp-instance-family-B,table:cvrp-instance-family-P}.
The idea is to generate new CVRP instances characterized by longer routes
so that we can evaluate the behavior of the proposed branch-and-cut pricer and labeling algorithm
as the routes they need to produce grow longer (see previous discussions in
\cref{sec:intro-thesis-contributions,sec:solving-the-pricing-problem}).
The new artificial instances were created as follows.
Let $Q \in R_+,\ k \in Z_+$ respectively denote the vehicle
capacity and the number of trucks of the unmodified CVRP instance.
Define a scale factor $s \in R_+$.
For each unmodified CVRP instance, we generate a new artificial instance
characterized by the vehicle capacity $Q^\prime \in R_+$
and by the number of vehicles $k^\prime \in Z_+$.
We've inflated the total number of available CVRP instances
by using the following relationship:
$$
	Q^\prime = Q \times s, \quad K^\prime = \ceil*{\frac{K}{s}}
$$
Inflation is performed for each unmodified CVRP instance by using
multiple values for the scale factor $s \in R_+$.
As $s \in R_+$ grows, the inflated CVRP instances will look more and more like a conventional TSP.
If $\ceil*{\frac{K}{s}} = 1$ the CVRP decades to a TSP and, as a result,
the BAP frameworks may become a suboptimal approach for dealing with such a problem.

\section{\bapcod{}}
\label{sec:results-bapcod}

\bapcod{} \parencite{sadykov2021} is a software package
developed in France at the Bordeaux University and Bordeaux Research Center
that embeds a sophisticated column generation approach
embedded in a generic and modern branch-price-and-cut (BPC) algorithm.
\bapcod{} takes a compact mixed-integer programming model as input
and solves it using a Dantzig-Wolfe reformulation \parencite{dantzig1960}.
See the previous discussion on \cref{sec:set-partitioning-formulation, sec:branch-and-price}.
The modern BPC solver automatically applies the Dantzig-Wolfe reformulation.
In this case, a default generic pricer based on a MIP optimizer
is employed during the column generation phase.
\bapcod{} uses an automatic dual price smoothing stabilization,
as discussed in \textcite{pessoa2018automation},
to improve the convergence speed of the column generation.
\bapcod{} supports direct branching on the master formulation's arc-flow variables
as well as Vanderbeck branching \parencite{vanderbeck2011}.
The latter is a non-robust branching scheme imposing bounds modifications on the sub-problem variables.
Because \bapcod{} is generic, it supports user-developed extensions
which can alter the BPC algorithm's behaviour.
These extensions can provide the BPC framework with
custom-defined cutting planes (robust and non-robust),
custom branching decisions (robust and non-robust),
or even ad-hoc pricer implementations.

The \vrpsolver{} extension \parencite{pessoa2020generic}, is
a \bapcod{} extension distributed by the same authors.
This extension includes an
advanced implementation of a bidirectional dynamic programming labeling algorithm
\parencite{sadykov2021bucket} for solving the pricing problem.
The included labeling algorithm
can be used as an exact or heuristic pricer.
The labeling algorithm contains two successively lighter heuristic implementations;
for more information, see \textcite{sadykov2021bucket}.
The labeling algorithm makes use of a generalized ng-sets definition \parencite{baldacci2011}
defined through the \textit{packing} and \textit{elementarity} sets,
as described in \textcite{pessoa2020generic}.
When the solution obtained after the CG convergence is fractional,
the ng-sets are dynamically augmented,
see \textcite{pessoa2020generic} for more details.
The \vrpsolver{} extension, also,
includes the implementation of some
specific cutting planes and branching decisions
aimed at efficiently solving routing-like problems
(or problems that exhibit similar structures)
such as the CVRP, VRPTW, and also others (see \cite{pessoa2020generic}).
The \vrpsolver{} implements the robust RCC cuts of \textcite{laporte1983},
and the non-robust limited-memory rank-1 cuts of \textcite{pecin2017improved}.
The \vrpsolver{} also implements the non-robust Ryan\&Foster branching \parencite{ryan1981integer}.
The \vrpsolver{} extension was also used successfully in \textcite{pessoa2020}
to solve the Bin Packing Problem (BPP).

\medskip

Currently, \bapcod{} and its \vrpsolver{} extension are the leading cutting-edge technologies
for solving vehicle routing problems \parencite{pessoa2020generic}.
The \bapcod{} source code is available for free, for academic purposes only,
by issuing a form request to this URL: \url{https://bapcod.math.u-bordeaux.fr/}.
The \vrpsolver{} extension, on the other hand, is only available in compiled form,
and must be explicitly requested via email by contacting one of the
original authors: \url{mailto:ruslan.sadykov@inria.fr}.
The official technical report presented in \textcite{sadykov2021} contains instructions
for building, configuring, and using \bapcod{} and its \vrpsolver{} extension.
To round things out, a Julia language interface to the \vrpsolver{} extension
can be found at this \urlref{https://github.com/inria-UFF/BaPCodVRPSolver.jl}{Github repo}.

For a comprehensive technical discussion of the components of
modern and advanced BPC frameworks, see \textcite{sadykov2019modern}.

\section{Evaluation Setup}
\label{sec:results-evaluation-setup}

The objective of this thesis, we recall, lies in verifying
whether a branch-and-cut framework can be competitive in solving
the pricing problem, especially if the lengths of the routes
that need to be produced increase in length.
We speculated that,
since the performance of the labeling algorithm deteriorates as the vehicle capacity increases,
a branch-and-cut framework could assist in solving the harder pricing problems.

It is clear, however, that the two frameworks operate very differently.
Our branch-and-cut framework does not support non-robust inequalities and variable fixing,
but produces very strong dual bounds.
Similarly, the labeling algorithm instead produces weaker dual bounds,
but it supports multiple column generation per pricing invocation,
non-robust cut generations and branching.
Therefore, comparing the performance of the two schemes is not an easy task.
So a natural question arises.
What is the best approach to compare the performance of the two frameworks?

\medskip

When faced with the option of developing our branch-and-cut pricer,
we had to opt between two main choices:
(i) developing our pricer in tight integration with the BPC framework,
by coding it as a \bapcod{} plugin,
or (ii) developing the pricer in a standalone executable,
separate from the BPC framework.

The first option has two main advantages.
First, it allows for our branch-and-cut pricer to influence the execution flow of the BPC algorithm.
Second, it enables to measure the effectiveness in pricing by comparing
the running time required to either solve the root-node or to solve the entire CVRP instance.
The downside of the first approach is however the complexity.

The second option, instead, it has one big advantage.
We can develop the pricer in full isolation, employing whichever programming
language or external library pleases us.
The implementation is simpler and more freedom in design choices can be attained.
However, since the branch-and-cut pricer cannot alter the execution of the BPC algorithm,
the only possible performance metric is the running time required to solve
each pricing iteration.
The branch-and-cut pricer, therefore, undergoes
the same execution flow that is generated from the BPC algorithm making use of the labeling algorithm.

\medskip

In the end we opted for simplicity, and we've decided to implement our pricer in a standalone executable.
As the performance comparison between the two approaches, we've decided to measure
the running time took for solving each pricing problem.
It has to be acknowledged, however, that measuring the running time of each pricing iteration
is nor good nor bad.
There are benefits and downsides to this approach.
First \bapcod{} needs to be configured to operate in the same domain as our pricer
thus disabling many features that could possibly lead to strong efficiency
when instead the whole running time is taken into consideration.
Secondly, our branch-and-cut pricer produces elementary bounds, thus naturally solves a harder problem.
While producing stronger bounds might be slower at the single pricing level, stronger bounds
may effectively skip some pricing iterations in the long run.
As an example, the branch-and-cut pricer may consistently appear two times slower with
respect to the labeling algorithm, but however, it might still
lead to a faster resolution of the overall CVRP.

Summing up, it is clear that the performance comparison that we've settled in, is just
a mere indicator of the true efficiency of the two approaches and must
therefore be taken cautiously.
We believe, however, there is still value in performing such a comparison as it lays
out a first proof-of-concept/direction regarding the feasibility of the effectiveness
of a branch-and-cut scheme for tackling the pricing problem.

\medskip

We conclude this section by introducing the \bapcod{} parametrization
that we've employed to bend the labeling algorithm to operate in
an environment that is compatible with our branch-and-cut algorithm.

The configuration parameters are specified separately
in an appropriately placed configuration file.
We've disabled the BPC framework's branching and cut-generation schemes.
Namely, the resolution process was asked to stop at
the root node of the branch-and-bound tree.
The ng-sets augmentation was enabled and the maximum ng-set threshold was configured
as high as possible. This was done to stress the labeling algorithm to generate dual bounds as close
as possible to the elementary bound at the end of each CG iteration.
The tailing off condition of the pricer was turned off.
We've also requested the labeling algorithm to output a single column per pricing invocation.
For a complete list of the configuration parameters
that  we've used refer to \Cref{sec:bapcod-appendix}.

\section{Evaluation Process}
\label{sec:results-evaluation-process}

We've employed \bapcod{} version 0.66 (released in November 2021) and the \texttt{libRCSP v0.5.12}.
The latter library contains the implementation of the \vrpsolver{} extension.
The objective is to exploit \bapcod{} to solve many CVRP instances while simultaneously
measuring the running time of the labeling algorithm for each pricing invocation.

\medskip

By following the \bapcod{} technical document \parencite{sadykov2021},
we've re-adapted one of the VRPTW example (included in the distribution),
to model a Capacitated Vehicle Routing Problem.
The master formulation that we've implemented follows the two-index arc flow model
presented in \cref{eq:two-index-flow-obj-func,eq:two-index-flow-two-edges-incident-per-customer,eq:two-index-flow-two-k-edges-incident-in-the-depot-node,eq:two-index-flow-ccc,eq:two-index-flow-x-mip-var-bounds-depot,eq:two-index-flow-x-mip-var-bounds},
excluding the Rounded Capacity Constraints (RCC) of \cref{eq:two-index-flow-ccc}.

In order to use the \vrpsolver{} labeling algorithm, it is necessary
to define the associated Resource Constrained Shortest Path (RCSP) sub-problem.
The RCSP sub-problem is formulated on a complete directed network by
linking the new RCSP modeling variables to the master problem formulation.
The RCSP sub-problem requires for the correct definition of the following:
the source/sink vertices and the so-called packing and elementarity sets
(see \cite{pessoa2020generic} for more details).
The elementarity and packing sets must be specified correctly for each customer.
The correct definition of these generalized sets is mandatory to allow for specific
components of the \vrpsolver{} extension to work correctly (ng-sets, RCC separation, etc).
A separate packing set and a separate elementarity set is created, one for each customer.
The \vrpsolver{} extension requires also for the explicit definition of an additional
distance matrix encoding the distance between pairs of elementarity sets.
The ng-sets are computed automatically by employing the elementarity sets
and the distance matrix specified from the user.

Due to implementation details, the RCSP sub-problem requires
the definition of the amount of resource consumption for each arc of the network.
It is not possible to define the resource consumption at the vertex level.
Therefore, as suggested in \textcite{pessoa2020generic}, we have defined the resource consumption
on the arcs as $q_{ij} = \frac{q_{i} + q_{j}}{2} \quad \forall i, j \in V$.
This definition is correct and it leads to a symmetric resource consumption ($q_{ij} = q_{ji}$).
The symmetric resource consumption property improves the efficiency in pricing,
by eliminating the need of performing backward labelling \parencite{pessoa2020generic}.

To extract the information needed for the performance evaluation we have implemented a custom pricing functor.
The pricing functor is in essence a glorified callback that can be used
for solving the pricing problem through custom user-defined code.
Our pricing functor is a simple stubbed implementation which ultimately invokes
the normal \vrpsolver{} extension's pricing functor.
However, before calling the labeling algorithm we first do the following.
First, we measure the running time of the labeling algorithm in order to assess its performance later.
Second, at each pricing invocation we record the dual variables $\pi \in \R^N$ of the RMP
to later be dumped into a dedicated file.

Due to \bapcod{}'s implementation details, the reduced cost of an
edge does not follow the simple relationship $\bar{c}_{ij} = c_{ij} - \frac{\pi_i + \pi_j}{2} \quad \forall i, j \in V,\ i \ne j$.
The dual variable $\pi_0 \in R$ can be retrieved from the user by accessing a field
of the master problem formulation.
The remaining dual variables $\pi_i \quad \forall i \in V_0$ must instead be computed
from the reduced cost of each edge $\bar{c}_{ij}$.
\bapcod{}, internally, uses the following relationship to encode the reduced cost of an edge:

\begin{equation}
	\bar{c}_{ij} = \begin{cases}
		c_{ij} - \frac{\pi_{j}}{2}       & \texttt{if } i = 0, j \in V_0       \\
		c_{ij} - \frac{\pi_i + \pi_j}{2} & \texttt{if } i, j \in V_0,\ i \ne j
	\end{cases}
\end{equation}

By exploiting the above relationship, we've implemented a trivial recursive algorithm
to extract all the necessary dual variables $\pi \in \R^N$.

In conclusion, at each pricing invocation we dump two files into disk.
The first file is a JSON file which contains metadata information about
the labeling algorithm, such as: the instance name, the instance size,
the total running time for the labeling, the reduced cost of the generated route,
the column generation iteration, etc.
The second file, instead, encodes a CPTP instance including:
the dual variables (i.e. the profits associated to each customer),
the original demands, the original node positions and finally the vehicle capacity.
The CPTP instance is encoded in a slightly modified TSPLIB95 file format.
We've introduced a dedicated \texttt{PROFIT\_SECTION} in the file format
to contain the extracted dual variables.

\subsection{Performance profiles}
\label{sec:results-performance-profiles}

\textit{Performance profiles} are a plot representation used to benchmark optimization software,
first presented in \textcite{dolan2002}.
Performance profiles are simple to interpret and less subject to personal interpretation.
In short, performance profiles plot the cumulative distribution function with respect to a performance metric.
We test $H$ algorithms by running them on $M$ problem instances.
In the X-axis, we plot the performance metric ratio with respect to a baseline.
The baseline is computed as the best performance achieved by all the algorithms under analysis.
The Y-axis instead shows the probability of being within an X ratio from the baseline.

\medskip

We've extensively employed performance profiles to compare the competitiveness of
our proposed branch-and-cut based pricer
against the RCSP dynamic programming algorithm used by \bapcod{} \parencite{pessoa2020generic}.

\begin{comment}
In this thesis, we will use performance profiles extensively to measure each solver by exploiting two performance metrics: \textbf{Time metric}, \textbf{Cost metric}.

A \textbf{Time performance profile} will tell us which resolution method is the fastest in terms of runtime.
A \textbf{Cost performance profile}, instead, will show us the cost ratio of the best upper bound obtained from each resolution method.
The ground truth optimal, as extracted from the dataset, is used instead as the cost baseline.
\end{comment}

\section{Empirical Results}
\label{sec:results-empirical-results}

\mytodo{Describe that only the last 10 pricing instances were used for comparison}

\mytodo{Describe operating system, processor speed, etc}

\mytodo{Introduce common issues in performance evaluation of chaotic systems. Solution through randomized runs with different starting seeds}

\mytodo{Report timelimit, seed values. num threads of the MIP optimizer}

\mytodo{Spam this section with performance profiles}

\begin{comment}
Each performance profile follows the syntax:
\begin{center}
	\begin{LVerbatim}
		<FAMILY-NAME>-scaled-<s>-last-10
	\end{LVerbatim}
\end{center}
where \texttt{<FAMILY>} denotes the CVRP instances family (i.e. E, F, etc) and \texttt{<s>} is the scale factor for the vehicle capacity.
The term \texttt{last-10} is used to denote that the performance profile uses only the last 10 pricing iterations for performing the comparison.

At the time of writing, only the following scaling factors were tested: $s = 1.0,\ s = 2.0,\ s = 4.0$.
\end{comment}

\begin{comment}
[@dparo: Old Gomoru HU Tree, It was slow and required amortization to speed up the BAC procedure]
In this implementation we employed the usage of both the push relabel algorithm,
the Gomory-Hu tree and full enumeration of all possible $(s, t)$ vertices.
Since running this full enumeration over each fractional separation,
turned out to be quite costly, we decided to amortize the cost over multiple iterations.
Namely, fractional separations iterations which are not multiple of $N$ become a no-op,
no maxflow is performed and therefore no set $S \subseteq V_0$ is separated.
\end{comment}

\section{Discussion of the Empirical Results}
\label{sec:results-discussion}

\mytodo{Discuss the performance profiles here}

\begin{comment}
\begin{landscape}
	\begin{table}[ht]
		\centering
		\begin{tabular}{l|lll|lll|lll|lll|}
			\multirow{3}{*}{Original CVRP Instance} & \multicolumn{6}{c|}{scaled 1.0} & \multicolumn{6}{c|}{scaled 2.0}                                                                                                                \\
			\cmidrule{2-7}
			                                        & \multicolumn{3}{c|}{libRCSP}    & \multicolumn{3}{c|}{BAC MIP}    & \multicolumn{3}{c|}{libRCSP} & \multicolumn{3}{c|}{BAC MIP}                                                  \\
			                                        & UB                              & LB                              & T [s]                        & UB                           & LB & T [s] & UB & LB & T [s] & UB & LB & T [s] \\
			\toprule
			A-n37                                   & x0                              & y0                              & t0                           & x1                           & y1 & t1    & x0 & y0 & t0    & x1 & y1 & t1    \\
			A-n38                                   & x2                              & y2                              & t2                           & x3                           & y3 & t3    & x2 & y2 & t2    & x3 & y3 & t3    \\
			\bottomrule
		\end{tabular}
	\end{table}
\end{landscape}

\end{comment}

\begin{comment}
\mytodo{Include the F-n135 grep result to talk about the difficulty of this instance and related ones}
\end{comment}
