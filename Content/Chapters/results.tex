\chapter{Results}
\label{sec:results}

\section{CVRP Benchmark Instances}
\label{sec:results-benchmark-instances}
To satisfactorily measure the competitiveness of our branch-an-cut pricer,
the usage of several CVRP benchmark instances is a mandatory necessity.
The \urlref{http://vrp.atd-lab.inf.puc-rio.br/index.php/en/}{CVRPLIB website}
is an online database for the vehicle routing problem
which it contains, among other things,
many freely downloadable CVRP test instances.
This very useful resource can be used
as a main point of reference by all the interested individuals.
It contains interactive plots of an exhaustive number of routing problems instances,
along with the best known/optimal solution found by the best scholars over the years.
Each CVRP test instance is stored in a file which filename follows a specific template of the form:

\begin{center}
	\begin{LVerbatim}
		<F>-n<N>-k<K>.vrp
	\end{LVerbatim}
\end{center}

where \texttt{.vrp} is the file extension,
\texttt{<N>} is the number of vertices in the instance,
\texttt{<K>} is the number of (maximum or exact) available vehicles
and finally \texttt{<F>} denotes the set instance family.
\texttt{<F>} is a single letter which uniquely identifies the instance
set along with the authors who published such set.
As an example \texttt{P-n40-k5.vrp} denotes a test instance composed
of $40$ nodes ($39$ customers) and $5$ vehicles.
The \texttt{P} in the name, indicates the instance set family, which in this
case it was published in \textcite{augerat1995}.

The contents of each CVRP instance file follows the \texttt{TSPLIB95} file format \parencite{reinelt1995}.
As it became usual for the TSP in \textcite{reinelt1991},
distances between pairs of nodes
is computed through a 2D Euclidean distance function
rounded to the nearest integer.
Rounding is done to make the optimal values more stable, so that the comparison between different contributions is achievable.
However, rounding introduces problems in comparing heuristic contributions, see \textcite{uchoa2017} for more details.

\medskip

To evaluate the performance of our pricer we used some of the most historic
and commonly known
CVRP instances:
set A, B, P \parencite{augerat1995}, set E \parencite{christofides1969},
set F \parencite{fisher1994}
and finally set M \parencite{christofides1979}.
The reader who's interested in knowing how such instances were obtained in the first
place, can refer to either the CVRPLIB website or to the work of \textcite{uchoa2017}.

\medskip
\mytodo{Put all the employed CVRP instances in tables. Similar as it is done in \cite{uchoa2017}}

\medskip

We've generated new artificial instances from the presented sets.
The idea is to generate new CVRP instances characterized by longer routes,
so that we can assess the behavior of the proposed branch-and-cut pricer
and the labeling algorithm respectively as the routes
they need to produce increase in length.
The new artificial instances were created in the following way.
Let $Q \in R_+,\ k \in Z_+$ respectively denote the vehicle
capacity and the number of trucks of the unmodified CVRP instance.
Define a scale factor $s \in R_+$.
For each unmodified CVRP instance, we generate a new artificial instance
characterized by the vehicle capacity $Q^\prime \in R_+$
and by the number of vehicles $k^\prime \in Z_+$.
We've inflated the total number of available CVRP instances
by using the following relationship:

$$
	Q^\prime = Q \times s, \quad k^\prime = \ceil*{\frac{k}{s}}
$$

The inflation is done for each unmodified CVRP instance and using
multiple values for the scale factor $s \in R_+$.

\section{\bapcod}
\label{sec:results-bapcod}

\textit{\bapcod}\ \parencite{sadykov2021} is a software package
developed in France at the Bordeaux University and Bordeaux Research Center,
which implements a sophisticated column generation approach
embedded inside a generic and modern branch-price-and-cut (BPC) algorithm.
\bapcod\ takes as input a compact mixed integer programming model,
and solves it by applying a Dantzig-Wolfe reformulation \parencite{dantzig1960}.
The reformulation is automatically applied by the solver
and a default generic pricer relying on
the usage of a MIP solver is employed in the column generation procedure.
An automatic dual price smoothing stabilization, discussed in \textcite{pessoa2018automation},
is applied by \bapcod\ to improve the convergence speed of the column generation.
\bapcod, being generic in nature,
supports user developed extensions.
\bapcod supports direct branching on the arc-flow flow variables of the master formulation
and Vanderbeck branching \parencite{vanderbeck2011}, a non-robust branching
scheme which imposes bounds modifications to the sub-problem variables.
These extensions can supply the BPC framework with either
custom defined cutting-planes (robust or non), custom branching decisions (robust or non)
or even ad-hoc pricer implementations.

The \textit{VRPSolver} extension \parencite{pessoa2020a}, is
a \bapcod\ extension distributed by the same authors.
This extension includes an
advanced implementation of a bidirectional dynamic programming labeling algorithm
\parencite{sadykov2021a} for solving the pricing problem.
The included labeling algorithm
can be both used as an exact pricer or as a heuristic one.
Precisely, it contains two successively lighter heuristic implementations, see \textcite{sadykov2021a} for more details.
The labeling algorithm makes use of a generalized ng-sets definition \parencite{baldacci2011}
defined through packing and elementarity sets as presented in \textcite{pessoa2020a}.
The ng-sets are dynamically augmented \parencite{roberti2014}
when the solution obtained after the column generation convergence
is fractional,
see \textcite{pessoa2020a} for more details.
The VRPSolver extension, also,
contains the implementation of some
specific cutting-planes and branching decisions
tailored at efficiently solving routing-like problems
(or problems that exhibit similar structures)
such as the CVRP, VRPTW and also others (see \cite{pessoa2020a}).
The VRPSolver implements the robust RCC cuts of \textcite{laporte1983},
and the non-robust limited-memory rank-1 cuts of \textcite{pecin2017}.
The VRPSolver also implements the non-robust branching called Ryan\&Foster branching \parencite{ryan1981}.
The VRPSolver extension was also successfully applied
to solve Bin Packing Problems in \textcite{pessoa2020}.

\medskip

\bapcod\ along with its VRPSolver extension are currently the leading state-of-the-art
technologies for solving vehicle routing problems \parencite{pessoa2020a}.
The \bapcod\ source code can be downloaded for free, for academic purposes only,
by issuing a form request at this url: \url{https://bapcod.math.u-bordeaux.fr/}.
The VRPSolver extension, instead, is available for academic use only in compiled form,
and must be explicitly requested by email by contacting one of the
original authors: \url{mailto:ruslan.sadykov@inria.fr}.
Instructions to build, setup and employ \bapcod\ and its VRPSolver extension
can be found in the official technical report presented in \textcite{sadykov2021}.
For completeness, we also report that
a Julia language interface to the VRPSolver extension
can be found at this
\urlref{https://github.com/inria-UFF/BaPCodVRPSolver.jl}{Github repo}.

Refer to \textcite{sadykov2019b},
for a complete technical discussion on the common ingredients of modern and advanced BPC frameworks.

\section{Evaluation Setup}
\label{sec:results-evaluation-setup}

The objective of this thesis, we recall, lies in verifying
whether a branch-and-cut framework can be competitive in solving
the pricing problem, especially if the lengths of the routes
that need to be produced increase in length.
We speculated that,
since the performance of the labeling algorithm deteriorates as the vehicle capacity increases,
a branch-and-cut framework could assist in solving the harder pricing problems.

It is clear, however, that the two frameworks operate very differently.
Our branch-and-cut framework does not support non-robust inequalities and variable fixing,
but produces very strong dual bounds.
Similarly, the labeling algorithm instead produces weaker dual bounds,
but it supports multiple column generation per pricing invocation,
non-robust cut generations and branching.
Therefore, comparing the performance of the two schemes is not an easy task.
So a natural question arises.
What is the best approach to compare the performance of the two frameworks?

\medskip

When faced with the option of developing our branch-and-cut pricer,
we had to opt between two main choices:
(i) developing our pricer in tight integration with the BPC framework,
by coding it as a \bapcod\ plugin,
or (ii) developing the pricer in a standalone executable,
separate from the BPC framework.

The first option has two main advantages.
First, it allows for our branch-and-cut pricer to influence the execution flow of the BPC algorithm.
Second, it enables to measure the effectiveness in pricing by comparing
the running time required to either solve the root-node or to solve the entire CVRP instance.
The downside of the first approach is however the complexity.

The second option, instead, it has one big advantage.
We can develop the pricer in full isolation, employing whichever programming
language or external library pleases us.
The implementation is simpler and more freedom in design choices can be attained.
However, since the branch-and-cut pricer cannot alter the execution of the BPC algorithm,
the only possible performance metric is the running time required to solve
each pricing iteration.
The branch-and-cut pricer, therefore, undergoes
the same execution flow that is generated from the BPC algorithm making use of the labeling algorithm.

\medskip

In the end we opted for simplicity, and we've decided to implement our pricer in a standalone executable.
As the performance comparison between the two approaches, we've decided to measure
the running time took for solving each pricing problem.
It has to be acknowledged, however, that measuring the running time of each pricing iteration
is nor good nor bad.
There are benefits and downsides to this approach.
First \bapcod\ needs to be configured to operate in the same domain as our pricer
thus disabling many features that could possibly lead to strong efficiency
when instead the whole running time is taken into consideration.
Secondly, our branch-and-cut pricer produces elementary bounds, thus naturally solves a harder problem.
While producing stronger bounds might be slower at the single pricing level, stronger bounds
may effectively skip some pricing iterations in the long run.
As an example, the branch-and-cut pricer may consistently appear two times slower with
respect to the labeling algorithm, but however, it might still
lead to a faster resolution of the overall CVRP.

Summing up, it is clear that the performance comparison that we've settled in, is just
a mere indicator of the true efficiency of the two approaches and must
therefore be taken cautiously.
We believe, however, there is still value in performing such a comparison as it lays
out a first proof-of-concept/direction regarding the feasibility of the effectiveness
of a branch-and-cut scheme for tackling the pricing problem.

\medskip

We conclude this section by introducing the \bapcod\ parametrization
that we've employed to bend the labeling algorithm to operate in
an environment that is compatible with our branch-and-cut algorithm.

The configuration parameters are specified separately
in an appropriately placed configuration file.
We've disabled the BPC framework's branching and cut-generation schemes.
Namely, the resolution process was asked to stop at
the root node of the branch-and-bound tree.
The ng-sets augmentation was enabled and the maximum ng-set threshold was configured
as high as possible. This was done to stress the labeling algorithm to generate dual bounds as close
as possible to the elementary bound at the end of each CG iteration.
The tailing off condition of the pricer was turned off.
We've also requested the labeling algorithm to output a single column per pricing invocation.
For a complete list of the configuration parameters
that  we've used refer to \Cref{sec:bapcod-appendix}.

\section{Evaluation Process}
\label{sec:results-evaluation-process}

We've employed \bapcod\ version 0.66 (released in November 2021) and the \texttt{libRCSP v0.5.12}.
The latter library contains the implementation of the VRPSolver extension.
The objective is to exploit \bapcod\ to solve many CVRP instances while simultaneously
measuring the running time of the labeling algorithm for each pricing invocation.

\medskip

By following the \bapcod\ technical document \parencite{sadykov2021},
we've re-adapted one of the VRPTW example (included in the distribution),
to model a Capacitated Vehicle Routing Problem.
The master formulation that we've implemented follows the two-index arc flow model
presented in \cref{eq:two-index-flow-obj-func,eq:two-index-flow-two-edges-incident-per-customer,eq:two-index-flow-two-k-edges-incident-in-the-depot-node,eq:two-index-flow-ccc,eq:two-index-flow-x-mip-var-bounds-depot,eq:two-index-flow-x-mip-var-bounds},
excluding the Rounded Capacity Constraints (RCC) of \cref{eq:two-index-flow-ccc}.

In order to use the VRPSolver labeling algorithm, it is necessary
to define the associated Resource Constrained Shortest Path (RCSP) sub-problem.
The RCSP sub-problem is formulated on a complete directed network by
linking the new RCSP modeling variables to the master problem formulation.
The RCSP sub-problem requires for the correct definition of the following:
the source/sink vertices and the so-called packing and elementarity sets (see \cite{pessoa2020a} for more details).
The elementarity and packing sets must be specified correctly for each customer.
The correct definition of these generalized sets is mandatory to allow for specific
components of the VRPSolver extension to work correctly (ng-sets, RCC separation, etc).
A separate packing set and a separate elementarity set is created, one for each customer.
The VRPSolver extension requires also for the explicit definition of an additional
distance matrix encoding the distance between pairs of elementarity sets.
The ng-sets are computed automatically by employing the elementarity sets
and the distance matrix specified from the user.

Due to implementation details, the RCSP sub-problem requires
the definition of the amount of resource consumption for each arc of the network.
It is not possible to define the resource consumption at the vertex level.
Therefore, as suggested in \textcite{pessoa2020a}, we have defined the resource consumption
on the arcs as $q_{ij} = \frac{q_{i} + q_{j}}{2} \quad \forall i, j \in V$.
This definition is correct and it leads to a symmetric resource consumption ($q_{ij} = q_{ji}$).
The symmetric resource consumption property improves the efficiency in pricing,
by eliminating the need of performing backward labelling \parencite{pessoa2020a}.

To extract the information needed for the performance evaluation we have implemented a custom pricing functor.
The pricing functor is in essence a glorified callback that can be used
for solving the pricing problem through custom user-defined code.
Our pricing functor is a simple stubbed implementation which ultimately invokes
the normal VRPSolver extension's pricing functor.
However, before calling the labeling algorithm we first do the following.
First, we measure the running time of the labeling algorithm in order to assess its performance later.
Second, at each pricing invocation we record the dual variables $\pi \in \R^N$ of the RMP
to later be dumped into a dedicated file.

Due to \bapcod's implementation details, the reduced cost of an
edge does not follow the simple relationship $\bar{c_{ij}} = c_{ij} - \frac{\pi_i + \pi_j}{2} \quad \forall i, j \in V,\ i \ne j$.
The dual variable $\pi_0 \in R$ can be retrieved from the user by accessing a field
of the master problem formulation.
The remaining dual variables $\pi_i \quad \forall i \in V_0$ must instead be computed
from the reduced cost of each edge $\bar{c_{ij}}$.
\bapcod, internally, uses the following relationship to encode the reduced cost of an edge:

\begin{equation}
	\bar{c_{ij}} = \begin{cases}
		c_{ij} - \frac{\pi_{j}}{2}       & \texttt{if } i = 0, j \in V_0       \\
		c_{ij} - \frac{\pi_i + \pi_j}{2} & \texttt{if } i, j \in V_0,\ i \ne j
	\end{cases}
\end{equation}

By exploiting the above relationship, we've implemented a trivial recursive algorithm
to extract all the necessary dual variables $\pi \in \R^N$.

In conclusion, at each pricing invocation we dump two files into disk.
The first file is a JSON file which contains metadata information about
the labeling algorithm, such as: the instance name, the instance size,
the total running time for the labeling, the reduced cost of the generated route,
the column generation iteration, etc.
The second file, instead, encodes a CPTP instance including:
the dual variables (i.e. the profits associated to each customer),
the original demands, the original node positions and finally the vehicle capacity.
The CPTP instance is encoded in a slightly modified TSPLIB95 file format.
We've introduced a dedicated \texttt{PROFIT\_SECTION} in the file format
to contain the extracted dual variables.

\subsection{Performance profiles}
\label{sec:results-performance-profiles}

\textit{Performance profiles} are a plot representation used to benchmark optimization software,
first presented in \textcite{dolan2002}.
Performance profiles are simple to interpret and less subject to personal interpretation.
In short, performance profiles plot the cumulative distribution function with respect to a performance metric.
We test $H$ algorithms by running them on $M$ problem instances.
In the X-axis, we plot the performance metric ratio with respect to a baseline.
The baseline is computed as the best performance achieved by all the algorithms under analysis.
The Y-axis instead shows the probability of being within an X ratio from the baseline.

\medskip

We've extensively employed performance profiles to compare the competitiveness of
our proposed branch-and-cut based pricer
against the RCSP dynamic programming algorithm used by \bapcod\ \parencite{pessoa2020a}.

\begin{comment}
In this thesis, we will use performance profiles extensively to measure each solver by exploiting two performance metrics: \textbf{Time metric}, \textbf{Cost metric}.

A \textbf{Time performance profile} will tell us which resolution method is the fastest in terms of runtime.
A \textbf{Cost performance profile}, instead, will show us the cost ratio of the best upper bound obtained from each resolution method.
The ground truth optimal, as extracted from the dataset, is used instead as the cost baseline.
\end{comment}

\section{Empirical Results}
\label{sec:results-empirical-results}

\mytodo{Tell that we've used only the last 10 pricing iterations for comparison}

\mytodo{Describe operating system, processor speed, etc}

\mytodo{Spam this section with performance profiles}

Each performance profile follows the syntax:
\begin{center}
	\begin{LVerbatim}
		<FAMILY-NAME>-scaled-<s>-last-10
	\end{LVerbatim}
\end{center}
where \texttt{<FAMILY>} denotes the CVRP instances family (i.e. E, F, etc) and \texttt{<s>} is the scale factor for the vehicle capacity.
The term \texttt{last-10} is used to denote that the performance profile uses only the last 10 pricing iterations for performing the comparison.

At the time of writing, only the following scaling factors were tested: $s = 1.0,\ s = 2.0,\ s = 4.0$.


\section{Discussion}
\label{sec:results-discussion}

\mytodo{Complete this section after populating the Empirical Results with the appropriate perf-profiles}

\begin{comment}
\mytodo{Include the F-n135 grep result to talk about the difficulty of this instance and related ones}
\end{comment}
